{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "_MySpeedTrack.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kgaurav3838/BCS_Workshop_Apr_20/blob/master/_MyMTechThesisProjectTracking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbZmHsEpoUXD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "591b2975-d549-4367-c470-b313d33ac4f7"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Mon June 1 22:47:29 2020\n",
        "Updated on Aug 27\n",
        "@author: Kumar Gaurav\n",
        "Institutions: EE, IIT Kanpur\n",
        "\n",
        "Title : Traffic Vehicle Detection, Tracking and Speed Estimation [Final main code]\n",
        "------------------------------------------------------------------\n",
        "calculates speed of vehicles in realtime in KMPH\n",
        "Added lateral distance tracking of two oppsite going vehicles\n",
        "computed acceleration\n",
        "\n",
        "key_formula =  ( speed in object plane / distance of camera from road ) = ( speed in image plane / focal length )\n",
        "approx fps of the video = 30\n",
        "\n",
        "to obtain accurate value distance to object (mm)  =   focal length (mm) * real height of the object (mm) * image height (pixels)\n",
        "                                                       ----------------------------------------------------------------\n",
        "                                                                 object height (pixels) * sensor height (mm)\n",
        "Sw\t13.2\t= the sensor width of the camera (millimeters)\t\n",
        "FR\t8.8\t= the focal length of the camera (millimeters)\t\n",
        "H (Drone height)\t100\t= the flight height (meters)\t\n",
        "imW\t4096\t= the image width (pixels)\t\n",
        "imH\t2160\t= the image height (pixels)\t\n",
        "GSD\t3.66\t= Ground Sampling Distance (centimeters/pixel)\t\n",
        "Dw\t150\t= width of single image footprint on the ground (meters)\t\n",
        "DH\t79\t= height of single image footprint on the ground (meters)\t\n",
        "\n",
        "1. Lens Focal Length in millimeters - 8.8 mm\n",
        "2. The sensor size\n",
        "Sensor Width - 13.2 mm\n",
        "Sensor Height - 8.8 mm\n",
        "Usage: knnSubtractor\n",
        "\"\"\"\n",
        "import cv2\n",
        "#from google.colab.patches import cv2_imshow # Colab cv2 imshow\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import deque\n",
        "import imutils as im\n",
        "import time\n",
        "import datetime\n",
        "import sys\n",
        "#sys.path.insert(0, \"/content/drive/My Drive/Colab Notebooks/\")\n",
        "#from align import alignImages\n",
        "\n",
        "def make_new_color():\n",
        "    return [random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)]\n",
        "def make_new_veh():\n",
        "    return [random.randint(1, 200)]\n",
        "\n",
        "def rotate_Frame_Video_Single(image, angle):  # For Single Videos\n",
        "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "    result = result[:,50:4000]\n",
        "    result1 = result.copy()\n",
        "    #result[:985 ,] = 0 ;result[1170: ,] = 0\n",
        "    result[:955 ,] = 0 ;result[1200: ,] = 0\n",
        "    return result, result1\n",
        "\n",
        "def rotate_Frame_Video_Stitched(image, angle):   # For Pyramid stitched videos\n",
        "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "    result0 = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "    result = np.zeros((image.shape[0]+400,image.shape[1],3), np.uint8)\n",
        "    result[100:1612,50:5500] = result0[:,50:5500]\n",
        "    result1 = result.copy()\n",
        "    #result[:985 ,] = 0 ;result[1170: ,] = 0\n",
        "    result[:751 ,] = 0 ;result[1000: ,] = 0   # 875\n",
        "    return result, result1\n",
        "\n",
        "def shadow_removal(img):\n",
        "    rgb_planes = cv2.split(img)\n",
        "    \n",
        "    result_planes = []\n",
        "    result_norm_planes = []\n",
        "    for plane in rgb_planes:\n",
        "        dilated_img = cv2.dilate(plane, np.ones((5,5), np.uint8))\n",
        "        bg_img = cv2.medianBlur(dilated_img, 21)\n",
        "        diff_img = 255 - cv2.absdiff(plane, bg_img)\n",
        "        norm_img = cv2.normalize(diff_img,None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
        "        result_planes.append(diff_img)\n",
        "        result_norm_planes.append(norm_img)\n",
        "    \n",
        "    result = cv2.merge(result_planes)\n",
        "    result_norm = cv2.merge(result_norm_planes)\n",
        "    return result_norm\n",
        "def canny_edge_detector(image): \n",
        "      \n",
        "    # Convert the image color to grayscale \n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)  \n",
        "      \n",
        "    # Reduce noise from the image \n",
        "    blur = cv2.GaussianBlur(gray_image, (5, 5), 0)  \n",
        "    canny = cv2.Canny(blur, 50, 150) \n",
        "    return canny \n",
        "def region_of_interest(image): \n",
        "    #height = image.shape[0] \n",
        "    '''polygons = np.array([ \n",
        "        [(200, height), (1100, height), (550, 250)]   # (width, height)\n",
        "        ]) '''\n",
        "    #polygons = np.array([[ (0, 900), (0,1250), (image.shape[1],1250), (image.shape[1], 900) ]])\n",
        "    #polygons = np.array([[ (0, 1030), (0,1150), (image.shape[1],1150), (image.shape[1], 1030) ]])\n",
        "    polygons = np.array([[ (0, 1100), (0,1230), (image.shape[1],1230), (image.shape[1], 1100) ]])\n",
        "    mask = np.zeros_like(image) \n",
        "    # Fill poly-function deals with multiple polygon \n",
        "    cv2.fillPoly(mask, polygons, 255)  \n",
        "      \n",
        "    # Bitwise operation between canny image and mask image \n",
        "    masked_image = cv2.bitwise_and(image, mask)  \n",
        "    return masked_image\n",
        "def getTransform(image, ty):\n",
        "    rows,cols = image.shape[:2]\n",
        "    #pts1 = np.float32([[50,50],[200,50],[50,200]])\n",
        "    #pts2 = np.float32([[10,100],[200,50],[100,250]])\n",
        "    #M = cv2.getAffineTransform(pts1,pts2)\n",
        "    ty = ty - cols\n",
        "    M = np.float32([[1,0,0],[0,1,ty]])\n",
        "    dst = cv2.warpAffine(image,M,(cols,rows))\n",
        "    return dst\n",
        "\n",
        "# Sensor Details:\n",
        "GSD = 0.0366 #3.66 cm/pixels\n",
        "Iw = 4096; Sw = 13.2 # in mm\n",
        "value = (GSD*Iw)/Sw\n",
        "f = 8.8; distance = 100 # approximated, real distance = (R/r)*(f*W/w)\n",
        "ratio = distance/f\n",
        "count = 0\n",
        "car_count = 0\n",
        "temp_new_ID = 0\n",
        "temp_count = 0\n",
        "\n",
        "#/content/drive/My Drive/Colab Notebooks/Videos/1stDrone.MP4\n",
        "# capt.Video frames from a video\n",
        "print(\"INFO: Video Starting\")\n",
        "#path = '/content/drive/My Drive/Colab Notebooks/Videos/1stDrone.MP4'\n",
        "#path = '/content/drive/My Drive/Colab Notebooks/Colab Notebooks/Videos/2ndDrone.MP4'\n",
        "pathc = '/content/drive/My Drive/Colab Notebooks/Colab Notebooks Anshu/Videos/_1stDrone_aligned.mp4'\n",
        "pathw =\"R:\\My Files\\OneDrive - IIT Kanpur\\Tracking Vehicles Data and Result\\Stabilized Drone Data\\Stabilized Videos Data\\_1stDrone_aligned.mp4\"\n",
        "pathw1 = \"R:/My Files/OneDrive - IIT Kanpur/Video Data/StitchData/_1stDrone_NewAlign_02.mp4\"  # Video_AlignPyramidStitch_117, Video_stitch_1+2_02\n",
        "pathw2 = \"R:/My Files/OneDrive - IIT Kanpur/Video Data/StitchData/alignVideos/Video_AlignPyramidStitch_115_01.mp4\"\n",
        "pathw3 = \"E:\\OneDrive - IIT Kanpur\\Tracking Vehicles Data and Result\\Stabilized Drone Data\\Stabilized Videos Data\\_1stDrone_aligned.mp4\"\n",
        "cap = cv2.VideoCapture(pathc)\n",
        "\n",
        "print(\"Video Open-\",cap.isOpened())\n",
        "# Subtractors\n",
        "sub = cv2.createBackgroundSubtractorMOG2()  # create background subtractor\n",
        "mogSubtractor = cv2.bgsegm.createBackgroundSubtractorMOG(300)\n",
        "mog2Subtractor = cv2.createBackgroundSubtractorMOG2() \n",
        "gmgSubtractor = cv2.bgsegm.createBackgroundSubtractorGMG(10, .8)\n",
        "knnSubtractor = cv2.createBackgroundSubtractorKNN()   #Very efficient if number of foreground pixels is low\n",
        "cntSubtractor = cv2.bgsegm.createBackgroundSubtractorCNT(5, True)\n",
        "es = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (20,12))\n",
        "\n",
        "centroids_list = deque([])\n",
        "car_count = 0\n",
        "temp1 = 0\n",
        "with open(\"lateral_distance.csv\", \"w\") as o:\n",
        "    pass\n",
        "\n",
        "#width = 1500 ; height = 820\n",
        "#width = 2000; height = 1093\n",
        "width = 2500; height = 1367\n",
        "#width = 3000; height = 832\n",
        "#frate = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "frate = 20\n",
        "#***************************************************************************************************************\n",
        "#path21 = 'D:/Gaurav/StitchData/VideoWrite/NewStitch3/_TrackVehicle_SingleDrone_Super_1.mp4' # Video write\n",
        "#path21 = \"D:/Gaurav/StitchData/VideoWrite/NewStitch3/TrackVehicle_SingleDrone_super8test.mp4\"\n",
        "#path21 = \"E:/CodeVideoData/Ultimate Trials/TrackVehicle_SingleDrone_superTest_02.mp4\"\n",
        "path21 = '/content/drive/My Drive/Colab Notebooks/Videos/_Track_Traffic_Vehicles_Colab_Ultimate_Test_32.mp4'\n",
        "writer = cv2.VideoWriter(path21, cv2.VideoWriter_fourcc(*'XVID'),frate, (width, height))\n",
        "\n",
        "frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT ))\n",
        "print(\"No. of frames:\", frames)\n",
        "\n",
        "print(\"INFO: Tracking is in Progress...\")\n",
        "frame_count = 0\n",
        "start = time.time()\n",
        "dist_dict = {}\n",
        "first_frame = False\n",
        "#cv2.namedWindow(\"output\", cv2.WINDOW_NORMAL)\n",
        "\n",
        "while True:\n",
        "\n",
        "    ret, frame = cap.read()  # import image\n",
        "    frame_count +=  1\n",
        "    if frame_count == 3600: # 7200, 3600, 3700, 3615, 5800\n",
        "      break\n",
        "    if frame_count < 3100:\n",
        "        continue\n",
        "\n",
        "    if  ret:  # if there is a frame continue with code\n",
        "        if first_frame:\n",
        "            imgRef = frame\n",
        "            first_frame = False\n",
        "\n",
        "        #frame = alignImages(frame, imgRef)\n",
        "        image, image2 = rotate_Frame_Video_Single(frame, 1.58) \n",
        "\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # converts image to gray\n",
        "        fg_mask = knnSubtractor.apply(gray)  #  mog2Subtractor  knnSubtractor\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
        "        value1, th = cv2.threshold(fg_mask, 5, 255, cv2.THRESH_BINARY)\n",
        "        opening = cv2.morphologyEx(th, cv2.MORPH_OPEN, kernel, iterations=1) #erosion followed by dilation, useful in removing noises\n",
        "        closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel, iterations=3) #Dilation followed by Erosion\n",
        "        dilation = cv2.dilate(closing, kernel, iterations = 1)\n",
        "        #closing = cv2.morphologyEx(dilation, cv2.MORPH_CLOSE, kernel, iterations=1) #Dilation followed by Erosion\n",
        "        '''        \n",
        "        dilation = cv2.dilate(opening, kernel, iterations=2) #adds pixels to the boundaries of objects in an image\n",
        "        #eroded = cv2.erode(dilation, kernel, iterations=1 ) #removes pixels on object boundaries        \n",
        "        '''\n",
        "        contours, hierarchy = cv2.findContours(dilation, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        minarea = 500\n",
        "        # max area for contours, can be quite large for buses\n",
        "        maxarea = 35000\n",
        "        # vectors for the x and y locations of contour centroids in current frame\n",
        "        '''cxx = np.zeros(len(contours))\n",
        "        cyy = np.zeros(len(contours))\n",
        "        '''\n",
        "        temp = 0\n",
        "        for i in range(len(contours)):  # cycles through all contours in current frame\n",
        "            if hierarchy[0, i, 3] == -1:  # using hierarchy to only count parent contours (contours not within others)\n",
        "                area = cv2.contourArea(contours[i])  # area of contour\n",
        "                if minarea < area < maxarea:  # area threshold for contour\n",
        "                    # calculating centroids of contours\n",
        "                    cnt = contours[i]\n",
        "                    M = cv2.moments(cnt)\n",
        "                    cx = int(M['m10'] / M['m00'])\n",
        "                    cy = int(M['m01'] / M['m00'])\n",
        "                    \n",
        "                    x, y, w, h = cv2.boundingRect(cnt)\n",
        "                    \n",
        "                    xA = x\n",
        "                    xB = x + w\n",
        "                    yA = y\n",
        "                    yB = y + h\n",
        "                    if w  > 320 or w < 50 or h < 22 or h > 90:\n",
        "                        continue\n",
        "                    if w > 320 and h > 90:\n",
        "                        continue\n",
        "                        \n",
        "                    not_matched = True\n",
        "                    noteIdx = -1\n",
        "                    for idx, centroid_data in enumerate(centroids_list):\n",
        "                        if centroid_data[0] == count:\n",
        "                            continue\n",
        "            \n",
        "                        # check proximity using manhattan distance\n",
        "                        X = (float(xA + xB) / 2 - float(centroid_data[2][0] + centroid_data[2][2]) / 2)\n",
        "                        Y = (float(yA + yB) / 2 - float(centroid_data[2][1] + centroid_data[2][3]) / 2)\n",
        "\n",
        "                        if abs(X) < 70 and abs(Y) < 15:  # 50,15(e)\n",
        "                            noteIdx = idx\n",
        "                            \n",
        "                            if h < 40 and abs(X) < 60 and abs(Y) < 10: #40,35\n",
        "                                #print(\"Bike ID:\", centroid_data[7], \":\",centroid_data[2], [xA,yA], X, Y)\n",
        "                                not_matched = False\n",
        "                                centroids_list[idx][2] = [xA, yA, xB, yB]\n",
        "                                #*********************************************************************************************************\n",
        "                                #centroids_list[idx][6].append(np.sqrt(X ** 2 + Y ** 2) * 60*value*3.6/100/2)\n",
        "                                centroids_list[idx][6][0].append(np.sqrt(X ** 2 + Y ** 2) * 60*3.6*ratio/100/2)\n",
        "                                if len(centroids_list[idx][6][0]) > 400:\n",
        "                                    centroids_list[idx][6][0].pop(0)\n",
        "                                    \n",
        "                                if centroids_list[idx][5] == \"unlocked\":\n",
        "                                    if centroids_list[idx][0] == count - 1:\n",
        "                                        centroids_list[idx][3] += 1\n",
        "                                        if X > 0:\n",
        "                                            centroids_list[idx][4][2] += 1  # To track towards right movements\n",
        "                                        else:\n",
        "                                            centroids_list[idx][4][3] += 1 # To track towards left movements\n",
        "                                    else:\n",
        "                                        centroids_list[idx][3] = 0\n",
        "                \n",
        "                                if centroids_list[idx][3] == 6:\n",
        "                                    centroids_list[idx][5] = \"locked\"\n",
        "                                    centroids_list[idx][3] = 0\n",
        "                                    if centroids_list[idx][4][2] > centroids_list[idx][4][3]:\n",
        "                                        centroids_list[idx][4] = [\"Bike(R)\", \"right\", 0, 0]\n",
        "                                    else:\n",
        "                                        centroids_list[idx][4] = [\"Bike(L)\", \"left\", 0, 0]\n",
        "                                        \n",
        "                                if centroids_list[idx][6][-1] != 0.0:\n",
        "                                    centroids_list[idx][6][1].append(int((sum(centroids_list[idx][6][0])/len(centroids_list[idx][6][0]))))\n",
        "                                    if len(centroids_list[idx][6][1]) > 10:\n",
        "                                        centroids_list[idx][6][1].pop(0)\n",
        "                                    cv2.rectangle(image, (xA, yA), (xB, yB), centroid_data[1], 2)  # (255,20,147) = pink color\n",
        "                                    cv2.putText(image, str(int(centroids_list[idx][6][1][-1]))+ str(\"KMPH\")  + str(\",ID=\") + str(centroids_list[idx][7]),\n",
        "                                                (xA, yA), cv2.FONT_HERSHEY_SIMPLEX, 1, (np.average(centroid_data[1])/2), 2, cv2.LINE_AA) \n",
        "                                    cv2.putText(image, str(centroids_list[idx][4][0]),(centroid_data[2][0]+90, centroid_data[2][1]+25) ,\n",
        "                                                cv2.FONT_HERSHEY_SIMPLEX, 1, (255,20,147), 2, cv2.LINE_AA)\n",
        "                                    \n",
        "                            elif h > 70 or w > 180:   #40, 185\n",
        "                                #print(\"Bus:\",h,w)\n",
        "                                not_matched = False\n",
        "                                centroids_list[idx][2] = [xA, yA, xB, yB]\n",
        "                                #*********************************************************************************************************\n",
        "                                #centroids_list[idx][6].append(np.sqrt(X ** 2 + Y ** 2) * 60*value*3.6/100/2)\n",
        "                                centroids_list[idx][6][0].append(np.sqrt(X ** 2 + Y ** 2) * 60*3.6*ratio/100/2)\n",
        "                                if len(centroids_list[idx][6][0]) > 400:\n",
        "                                    centroids_list[idx][6][0].pop(0)\n",
        "                                    \n",
        "                                if centroids_list[idx][5] == \"unlocked\":\n",
        "                                    if centroids_list[idx][0] == count - 1:\n",
        "                                        centroids_list[idx][3] += 1\n",
        "                                        if X > 0:\n",
        "                                            centroids_list[idx][4][2] += 1  # To track towards right movements\n",
        "                                        else:\n",
        "                                            centroids_list[idx][4][3] += 1 # To track towards left movements\n",
        "                                    else:\n",
        "                                        centroids_list[idx][3] = 0\n",
        "                                else:\n",
        "                                    if X > 0:\n",
        "                                        centroids_list[idx][4][2] = [\"Bus(R)\", \"right\", 0, 0]\n",
        "                                    else:\n",
        "                                        centroids_list[idx][4][3] = [\"Bus(R)\", \"right\", 0, 0]\n",
        "                \n",
        "                                if centroids_list[idx][3] == 15:\n",
        "                                    centroids_list[idx][5] = \"locked\"\n",
        "                                    centroids_list[idx][3] = 0\n",
        "                                    if centroids_list[idx][4][2] > centroids_list[idx][4][3]:\n",
        "                                        centroids_list[idx][4] = [\"Bus(R)\", \"right\", 0, 0]\n",
        "                                    else:\n",
        "                                        centroids_list[idx][4] = [\"Bus(L)\", \"left\", 0, 0]\n",
        "                                        \n",
        "                                if centroids_list[idx][6][-1] != 0.0:\n",
        "                                    centroids_list[idx][6][1].append(int((sum(centroids_list[idx][6][0])/len(centroids_list[idx][6][0]))))\n",
        "                                    if len(centroids_list[idx][6][1]) > 10:\n",
        "                                        centroids_list[idx][6][1].pop(0)\n",
        "                                    cv2.rectangle(image, (xA, yA), (xB, yB), centroid_data[1], 2)\n",
        "                                    cv2.putText(image, str(int(centroids_list[idx][6][1][-1]))+ str(\"KMPH\")  + str(\",ID=\") + str(centroids_list[idx][7]),\n",
        "                                                (xA, yA), cv2.FONT_HERSHEY_SIMPLEX, 1, (np.average(centroid_data[1])/2), 2, cv2.LINE_AA) \n",
        "                                    cv2.putText(image, str(centroids_list[idx][4][0]),(centroid_data[2][0], centroid_data[2][1]+40) ,\n",
        "                                                cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,20,147), 2, cv2.LINE_AA)\n",
        "                            else:          \n",
        "                                #print(\"Car ID:\", centroid_data[7], \":\",centroid_data[2], [xA,yA], X, Y, h,w)\n",
        "                                not_matched = False\n",
        "                                centroids_list[idx][2] = [xA, yA, xB, yB]\n",
        "                                #*********************************************************************************************************\n",
        "                                #centroids_list[idx][6].append(np.sqrt(X ** 2 + Y ** 2) * 60*value*3.6/100/2)\n",
        "                                centroids_list[idx][6][0].append(np.sqrt(X ** 2 + Y ** 2) * 60*3.6*ratio/100/2)\n",
        "                                if len(centroids_list[idx][6][0]) > 400:\n",
        "                                    centroids_list[idx][6][0].pop(0)\n",
        "                                    \n",
        "                                if centroids_list[idx][5] == \"unlocked\":\n",
        "                                    if centroids_list[idx][0] == count - 1:\n",
        "                                        centroids_list[idx][3] += 1\n",
        "                                        if X > 0:\n",
        "                                            centroids_list[idx][4][2] += 1  # To track towards right movements\n",
        "                                        else:\n",
        "                                            centroids_list[idx][4][3] += 1 # To track towards left movements\n",
        "                                    else:\n",
        "                                        centroids_list[idx][3] = 0\n",
        "                \n",
        "                                if centroids_list[idx][3] == 16:\n",
        "                                    centroids_list[idx][5] = \"locked\"\n",
        "                                    centroids_list[idx][3] = 0\n",
        "                                    if centroids_list[idx][4][2] > centroids_list[idx][4][3]:\n",
        "                                        centroids_list[idx][4] = [\"Car(R)\", \"right\", 0, 0]\n",
        "                                    else:\n",
        "                                        centroids_list[idx][4] = [\"Car(L)\", \"left\", 0, 0]\n",
        "                                        \n",
        "                                if centroids_list[idx][6][-1] != 0.0:\n",
        "                                    centroids_list[idx][6][1].append(int((sum(centroids_list[idx][6][0])/len(centroids_list[idx][6][0]))))\n",
        "                                    if len(centroids_list[idx][6][1]) > 10:\n",
        "                                        centroids_list[idx][6][1].pop(0)\n",
        "                                    cv2.rectangle(image, (xA, yA), (xB, yB), centroid_data[1], 2)\n",
        "                                    cv2.putText(image, str(int(centroids_list[idx][6][1][-1]))+ str(\"KMPH\")  + str(\",ID=\") + str(centroids_list[idx][7]),\n",
        "                                                (xA, yA), cv2.FONT_HERSHEY_SIMPLEX, 1, (np.average(centroid_data[1])/2), 2, cv2.LINE_AA) \n",
        "                                    cv2.putText(image, str(centroids_list[idx][4][0]),(centroid_data[2][0], centroid_data[2][1]+40) ,\n",
        "                                                cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,20,147), 2, cv2.LINE_AA)\n",
        "                                \n",
        "                            centroids_list[idx][0] = count\n",
        "                            \n",
        "                            break\n",
        "            \n",
        "                    if not_matched:\n",
        "                        if count < 125:\n",
        "                            color = make_new_color()\n",
        "                            # append new rectangle in previous cars list\n",
        "                            #car_count = random.randint(50, 200) \n",
        "                            centroids_list.appendleft([count, color, (xA, yA, xB, yB), 1, [\"NA\", \"NA\", 0, 0], \"unlocked\", [[0], [0]], car_count])\n",
        "                            car_count += 1\n",
        "                            print(\"Vehicle No.:\", centroids_list[0][7],\"arrived\")\n",
        "                            new_ID = True\n",
        "                        elif xA < 600 or xA > 3500:\n",
        "                            color = make_new_color()\n",
        "                            # append new rectangle in previous cars list\n",
        "                            #car_count = random.randint(50, 200) \n",
        "                            centroids_list.appendleft([count, color, (xA, yA, xB, yB), 1, [\"NA\", \"NA\", 0, 0], \"unlocked\", [[0], [0]], car_count])\n",
        "                            car_count += 1\n",
        "                            print(\"Vehicle No.:\", centroids_list[0][7],\"arrived\")\n",
        "                            new_ID = True\n",
        "                        \n",
        "                    #print(\"centroids:\",centroids_list[noteIdx][7],centroids_list[noteIdx][5],centroids_list[noteIdx][4][1],noteIdx)\n",
        "                    # Computing lateral distances of nearby locked vehicles\n",
        "                    for idx, centroid_data in enumerate(centroids_list):\n",
        "                        if  noteIdx != -1 and centroids_list[noteIdx][5] == \"locked\" and centroids_list[noteIdx][4][1] == \"right\":\n",
        "                            if abs(centroids_list[idx][2][0] - centroids_list[noteIdx][2][0]) < 100 :\n",
        "                                if centroids_list[idx][4][1] == \"left\":\n",
        "                                    lateral_dist = abs(centroids_list[noteIdx][2][3] - centroids_list[idx][2][1])\n",
        "                                    accelearation = (abs(centroids_list[noteIdx][6][1][-1]-centroids_list[noteIdx][6][1][-2]))//60\n",
        "                                    #accelearationCar = (abs(speedCar[-1]-speedCar[-2]))//60\n",
        "                                    #accelearationBus = (abs(speedBus[-1]-speedBus[-2]))//60\n",
        "                                    #print(\"acceleration=\",accelearation)\n",
        "                                    #print(\"ID =\",centroids_list[noteIdx][7],centroids_list[idx][7],\"Lat Dist=\", lateral_dist)\n",
        "                                    (x1, y1) = (int((centroids_list[noteIdx][2][0] + centroids_list[noteIdx][2][2])/2),centroids_list[noteIdx][2][3])\n",
        "                                    (x2, y2) = (int((centroids_list[idx][2][0] + centroids_list[idx][2][2])/2),centroids_list[idx][2][1])\n",
        "                                    #cv2.line(image, (x1, y1), (x2, y2), [0,0,255], 4)\n",
        "                                    #Writing into a csv file\n",
        "                                    with open(\"lateral_distance.csv\", \"a\") as o:\n",
        "                                        o.write(str(\"lateral distance between IDs: \") + str(centroids_list[noteIdx][7]) + str(\" and \") + str(centroids_list[idx][7]) + \" = \" + str(lateral_dist) + \"\\n\")\n",
        "                                    cv2.putText(image, str(\"Lateral distance between IDs: \")+ str(centroids_list[noteIdx][7]) + str(\" and \") + str(centroids_list[idx][7]) + \" = \" + str(lateral_dist),\n",
        "                                                (2350, image.shape[0] - 495 + temp), cv2.FONT_HERSHEY_SIMPLEX, 2.0, (0, 0, 200), 3)\n",
        "                                    temp += 50\n",
        "                        \n",
        "                    if centroids_list[0][5] == \"locked\":\n",
        "                        for veh_ID in range(len(centroids_list)):\n",
        "                            temp_new_ID += 70\n",
        "                            cv2.putText(image, str(centroids_list[veh_ID][4][0]) + str(\"  with \") + str(\"ID-\") +  str(centroids_list[veh_ID][7]) + str(\"  has arrived\"),   \n",
        "                                    (50, image.shape[0] - 520 + temp_new_ID),cv2.FONT_HERSHEY_SIMPLEX, 1.8, (0, 200, 200), 3)\n",
        "                        if veh_ID == len(centroids_list) -1:\n",
        "                            temp_new_ID = 0\n",
        "                    centroids_list = deque([car_data for car_data in list(centroids_list) if count - car_data[0] < 100])\n",
        "\n",
        "                            \n",
        "    image[500:955 ,] = image2[500:955, ] ;image[1200:1600 ,] = image2[1200:1600 ,]  # 970(e), 955(n)   # For single video\n",
        "    #image[150:651 ,] = image2[150:651, ] ;image[900:1300 ,] = image2[900:1300 ,]  # 970(e), 955(n)  # FOR STICHED VIDEOS\n",
        "    image[(image.shape[0] - 110):image.shape[0] , int(image.shape[1]*0.62):] = 255\n",
        "    timestamp = datetime.datetime.now()\n",
        "    ts = timestamp.strftime(\" %d %B %Y %I:%M:%S%p\")\n",
        "\n",
        "    cv2.putText(image, str(\"R-\") + str(\"means\") +  str(\" going towards right\"), (1250, image.shape[0] - 140),  \n",
        "        cv2.FONT_HERSHEY_SIMPLEX, 2.0, (0, 150, 200), 3)\n",
        "    cv2.putText(image, str(\"L-\") + str(\"means\") +  str(\" going towards left\"), (1250, image.shape[0] - 40),  \n",
        "        cv2.FONT_HERSHEY_SIMPLEX, 2.0, (0, 150, 200), 3)\n",
        "    cv2.putText(image, \"Drone (Bird's Eye View)\", (1400, 150),  \n",
        "        cv2.FONT_HERSHEY_SIMPLEX, 4.0, (255, 255, 0), 3)\n",
        "    cv2.putText(image, \"[Traffic Vehicles Detection, Tracking and Speed Estimation]\", (600, 300),  \n",
        "        cv2.FONT_HERSHEY_SIMPLEX, 3.0, (255, 0, 200), 3)\n",
        "    cv2.putText(image, ts, (2500, image.shape[0] - 20),  \n",
        "        cv2.FONT_HERSHEY_SIMPLEX, 3.0, (0, 0, 200), 3)  # TimeStamp\n",
        "    cv2.putText(image, \"Drone-1\", (1400,350),\n",
        "        cv2.FONT_HERSHEY_SIMPLEX, 5, (0, 0, 0), 4) # Drone-1\n",
        "    cv2.putText(image, \"Drone-2\", (4000, 350),\n",
        "        cv2.FONT_HERSHEY_SIMPLEX, 5, (0, 0, 0), 4) # Drone-2\n",
        "    #cv2.imwrite(\"img.png\",image)\n",
        "    image = im.resize(image, 2500)\n",
        "    writer.write(image)\n",
        "    #cv2.imshow('output', image)\n",
        "    # Wait for Esc key to stop\n",
        "    if cv2.waitKey(33) == 27:\n",
        "        break \n",
        "    # outputs all the video frames into out folder present in the working directory\n",
        "    #cv2.imwrite(\"/content/drive/My Drive/Colab Notebooks/out/\" + str(count) + \".jpg\", image)\n",
        "    count += 1\n",
        "    #print(\"Frame Count=\",count)\n",
        "\n",
        "print(\"Number of vehicle crossed = \", car_count)\n",
        "print(\"Number of frames processed = \", frame_count)\n",
        "Time_Elapsed = time.time()-start\n",
        "print(\"Time Elapsed=\",Time_Elapsed,'s')\n",
        "print(\"finished Successfully\")\n",
        "print(image.shape)\n",
        "cap.release()\n",
        "writer.release()\n",
        "cv2.destroyAllWindows()\n",
        "# Output: https://drive.google.com/drive/folders/12HLHqqccQvQoCJFofr83Kava4-CcVcK3 \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO: Video Starting\n",
            "Video Open- True\n",
            "No. of frames: 5870\n",
            "INFO: Tracking is in Progress...\n",
            "Vehicle No.: 0 arrived\n",
            "Vehicle No.: 1 arrived\n",
            "Vehicle No.: 2 arrived\n",
            "Vehicle No.: 3 arrived\n",
            "Vehicle No.: 4 arrived\n",
            "Vehicle No.: 5 arrived\n",
            "Vehicle No.: 6 arrived\n",
            "Vehicle No.: 7 arrived\n",
            "Vehicle No.: 8 arrived\n",
            "Vehicle No.: 9 arrived\n",
            "Vehicle No.: 10 arrived\n",
            "Vehicle No.: 11 arrived\n",
            "Vehicle No.: 12 arrived\n",
            "Vehicle No.: 13 arrived\n",
            "Vehicle No.: 14 arrived\n",
            "Vehicle No.: 15 arrived\n",
            "Vehicle No.: 16 arrived\n",
            "Number of vehicle crossed =  17\n",
            "Number of frames processed =  3600\n",
            "Time Elapsed= 309.75139236450195 s\n",
            "finished Successfully\n",
            "(1367, 2500, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0W28zCsC4sy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "3cb36599-1562-4f44-de74-2d04f169a1c3"
      },
      "source": [
        "# Locations: /content/drive/My Drive/Colab Notebooks/\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Mon June 1 22:47:29 2020\n",
        "Updated on Mon June 12\n",
        "@author: Kumar Gaurav\n",
        "Institutions: EE, IIT Kanpur\n",
        "\n",
        "Title : Traffic Vehicle Speed Estimation\n",
        "------------------------------------------------------------------\n",
        "calculates speed of vehicles in realtime in KMPH\n",
        "this code mainly focusses on detecting and tracking cars by using trained  classifier which already has features of cars\n",
        "\n",
        "key_formula =  ( speed in object plane / distance of camera from road ) = ( speed in image plane / focal length )\n",
        "approx fps of the video = 30\n",
        "\n",
        "to obtain accurate value distance to object (mm)  =   focal length (mm) * real height of the object (mm) * image height (pixels)\n",
        "                                                       ----------------------------------------------------------------\n",
        "                                                                 object height (pixels) * sensor height (mm)\n",
        "Default Code\n",
        "Updated 29 Jun 20\n",
        "\"\"\"\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow # Colab cv2 imshow\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import deque\n",
        "import imutils as im\n",
        "import time\n",
        "\n",
        "\n",
        "def make_new_color():\n",
        "    return [random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)]\n",
        "def make_new_veh():\n",
        "    return [random.randint(1, 50)]\n",
        "def rotate_image(image, angle):\n",
        "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "    result = result[:,50:4000]\n",
        "    result1 = result.copy()\n",
        "    result[:985 ,] = 0 ;result[1170: ,] = 0\n",
        "    return result, result1\n",
        "def shadow_removal(img):\n",
        "    rgb_planes = cv2.split(img)\n",
        "    \n",
        "    result_planes = []\n",
        "    result_norm_planes = []\n",
        "    for plane in rgb_planes:\n",
        "        dilated_img = cv2.dilate(plane, np.ones((5,5), np.uint8))\n",
        "        bg_img = cv2.medianBlur(dilated_img, 21)\n",
        "        diff_img = 255 - cv2.absdiff(plane, bg_img)\n",
        "        norm_img = cv2.normalize(diff_img,None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
        "        result_planes.append(diff_img)\n",
        "        result_norm_planes.append(norm_img)\n",
        "    \n",
        "    result = cv2.merge(result_planes)\n",
        "    result_norm = cv2.merge(result_norm_planes)\n",
        "    return result_norm\n",
        "\n",
        "# Sensor Details:\n",
        "GSD = 0.0366 #3.66 cm/pixels\n",
        "Iw = 4096; Sw = 13.2 # in mm\n",
        "value = (GSD*Iw)/Sw\n",
        "f = 8.8; distance = 100 # approximated, real distance = (R/r)*(f*W/w)\n",
        "ratio = distance/f\n",
        "count = 0\n",
        "\n",
        "#/content/drive/My Drive/Colab Notebooks/Videos/1stDrone.MP4\n",
        "# capt.Video frames from a video\n",
        "print(\"INFO: Video Starting\")\n",
        "path = '/content/drive/My Drive/Colab Notebooks/Videos/1stDrone.MP4'\n",
        "cap = cv2.VideoCapture(path)\n",
        "\n",
        "print(\"Video Open-\",cap.isOpened())\n",
        "# Subtractors\n",
        "sub = cv2.createBackgroundSubtractorMOG2()  # create background subtractor\n",
        "mogSubtractor = cv2.bgsegm.createBackgroundSubtractorMOG(300)\n",
        "mog2Subtractor = cv2.createBackgroundSubtractorMOG2() \n",
        "gmgSubtractor = cv2.bgsegm.createBackgroundSubtractorGMG(10, .8)\n",
        "knnSubtractor = cv2.createBackgroundSubtractorKNN()   #Very efficient if number of foreground pixels is low\n",
        "cntSubtractor = cv2.bgsegm.createBackgroundSubtractorCNT(5, True)\n",
        "es = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (20,12))\n",
        "\n",
        "centroids_list = deque([])\n",
        "car_count = 0\n",
        "'''with open(\"/content/drive/My Drive/Colab Notebooks/out1.csv\", \"w\") as o:\n",
        "    pass'''\n",
        "\n",
        "#width = 1500 ; height = 820\n",
        "width = 2000; height = 1093\n",
        "#frate = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "frate = 10\n",
        "#***************************************************************************************************************\n",
        "path21 = '/content/drive/My Drive/Colab Notebooks/Videos/_Track_KNN_final20.mp4' # Video write\n",
        "writer = cv2.VideoWriter(path21, cv2.VideoWriter_fourcc(*'XVID'),frate, (width, height))\n",
        "\n",
        "print(\"INFO: Tracking is in Progress...\")\n",
        "frame_count = 0\n",
        "start = time.time()\n",
        "\n",
        "while True:\n",
        "\n",
        "    ret, frame = cap.read()  # import image\n",
        "    frame_count +=  1\n",
        "    if frame_count == 5:  #3627\n",
        "      break\n",
        "\n",
        "    if  ret:  # if there is a frame continue with code\n",
        "        image, image2 = rotate_image(frame, 1.78)\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # converts image to gray\n",
        "        image1 = shadow_removal(gray)\n",
        "        fg_mask = knnSubtractor.apply(image1)  #  mog2Subtractor  knnSubtractor\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
        "        value, th = cv2.threshold(fg_mask, 10, 255, cv2.THRESH_BINARY)\n",
        "        opening = cv2.morphologyEx(th, cv2.MORPH_OPEN, kernel, iterations=1) #erosion followed by dilation, useful in removing noises\n",
        "        closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel, iterations=3) #Dilation followed by Erosion\n",
        "        dilation = cv2.dilate(closing, kernel, iterations = 1)\n",
        "        '''        \n",
        "        dilation = cv2.dilate(opening, kernel, iterations=2) #adds pixels to the boundaries of objects in an image\n",
        "        #eroded = cv2.erode(dilation, kernel, iterations=1 ) #removes pixels on object boundaries        \n",
        "        '''\n",
        "        contours, hierarchy = cv2.findContours(dilation, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        minarea = 700\n",
        "        # max area for contours, can be quite large for buses\n",
        "        maxarea = 18000\n",
        "        # vectors for the x and y locations of contour centroids in current frame\n",
        "        '''cxx = np.zeros(len(contours))\n",
        "        cyy = np.zeros(len(contours))\n",
        "        '''\n",
        "        for i in range(len(contours)):  # cycles through all contours in current frame\n",
        "            if hierarchy[0, i, 3] == -1:  # using hierarchy to only count parent contours (contours not within others)\n",
        "                area = cv2.contourArea(contours[i])  # area of contour\n",
        "                if minarea < area < maxarea:  # area threshold for contour\n",
        "                    # calculating centroids of contours\n",
        "                    cnt = contours[i]\n",
        "                    M = cv2.moments(cnt)\n",
        "                    cx = int(M['m10'] / M['m00'])\n",
        "                    cy = int(M['m01'] / M['m00'])\n",
        "                    \n",
        "                    x, y, w, h = cv2.boundingRect(cnt)\n",
        "                    \n",
        "                    xA = x\n",
        "                    xB = x + w\n",
        "                    yA = y\n",
        "                    yB = y + h\n",
        "                    if w  > 300 or w < 50:\n",
        "                        continue\n",
        "                    elif h < 20 or h > 90:\n",
        "                        continue\n",
        "                    elif w > 300 and h > 90:\n",
        "                        continue\n",
        "                        \n",
        "                    not_matched = True\n",
        "                    for idx, centroid_data in enumerate(centroids_list):\n",
        "                        if centroid_data[0] == count:\n",
        "                            continue\n",
        "                        if centroids_list[idx][4] == 0:\n",
        "                            centroids_list[idx][5] = \"unlocked\"\n",
        "                            centroids_list[idx][4] = 5\n",
        "            \n",
        "                        # check proximity using manhattan distance\n",
        "                        X = abs(float(centroid_data[2][0] + centroid_data[2][2]) / 2 - float(xA + xB) / 2)\n",
        "                        Y = abs(float(centroid_data[2][1] + centroid_data[2][3]) / 2 - float(yA + yB) / 2)\n",
        "\n",
        "                        if X < 35 and Y < 3:\n",
        "            \n",
        "                            not_matched = False\n",
        "                            centroids_list[idx][4] = 5\n",
        "                            centroids_list[idx][2] = [xA, yA, xB, yB]\n",
        "                            #*********************************************************************************************************\n",
        "                            #centroids_list[idx][6].append(np.sqrt(X ** 2 + Y ** 2) * 60*value*3.6/100/2)\n",
        "                            centroids_list[idx][6].append(np.sqrt(X ** 2 + Y ** 2) * 60*3.6*ratio/100/2)\n",
        "                            if centroids_list[idx][5] == \"unlocked\":\n",
        "            \n",
        "                                if centroids_list[idx][0] == count - 1:\n",
        "                                    centroids_list[idx][3] += 1\n",
        "            \n",
        "                                else:\n",
        "                                    centroids_list[idx][3] = 0\n",
        "            \n",
        "                            if centroids_list[idx][3] == 3:\n",
        "                                centroids_list[idx][5] = \"locked\"\n",
        "                                centroids_list[idx][3] = 0\n",
        "                            if centroids_list[idx][6][-1] != 0.0:\n",
        "                                cv2.rectangle(image, (xA, yA), (xB, yB), centroid_data[1], 2)\n",
        "                                cv2.putText(image, str(int(centroids_list[idx][6][-1]))+ str(\"KMPH\") + str(\",ID=\") + str(centroids_list[idx][7]),\n",
        "                                            (xA, yA), cv2.FONT_HERSHEY_SIMPLEX, 1, (np.average(centroid_data[1])/2), 0, cv2.LINE_AA) \n",
        "                                if h < 40:\n",
        "                                    cv2.putText(image, str(\"bike\"),\n",
        "                                                (centroid_data[2][0], centroid_data[2][1]+40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,20,147), 1, cv2.LINE_AA)\n",
        "                                elif h > 40 and w > 200:\n",
        "                                    cv2.putText(image, str(\"Bus\"),\n",
        "                                                (centroid_data[2][0], centroid_data[2][1]+40), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,20,147), 2, cv2.LINE_AA)\n",
        "                                else:\n",
        "                                    cv2.putText(image, str(\"Car\"),\n",
        "                                                (centroid_data[2][0], centroid_data[2][1]+40), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,20,147), 2, cv2.LINE_AA)\n",
        "                                \n",
        "                            centroids_list[idx][0] = count\n",
        "                            break\n",
        "            \n",
        "                    if not_matched:\n",
        "                        color = make_new_color()\n",
        "            \n",
        "                        # append new rectangle in previous cars list\n",
        "                        car_count = random.randint(1, 40) \n",
        "                        centroids_list.appendleft([count, color, (xA, yA, xB, yB), 1, 5, \"unlocked\", [0], car_count])\n",
        "                        #car_count += 1\n",
        "                        # cv2.rectangle(image, (xA, yA), (xB, yB), color, 2)\n",
        "                        # cv2.putText(image, \"0\",\n",
        "                        #             (xA, yA), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1, cv2.LINE_AA)\n",
        "                        prev_color = color\n",
        "                        prev_coords = [xA, yA, xB, yB]\n",
        "            \n",
        "                    # plot all remaining locked rectangles\n",
        "                    for idx, centroid_data in enumerate(centroids_list):\n",
        "                \n",
        "                        if centroid_data[5] == \"locked\" and centroid_data[0] != count:\n",
        "                            centroids_list[idx][4] -= 1\n",
        "                            if centroids_list[idx][6][-1] != 0.0:\n",
        "                                cv2.rectangle(image, (centroid_data[2][0], centroid_data[2][1]), (centroid_data[2][2], centroid_data[2][3]),\n",
        "                                              centroid_data[1], 2)\n",
        "\n",
        "                                cv2.putText(image, str(int(centroids_list[idx][6][-1])) + str(\"KMPH\") + str(\",ID=\") + str(centroids_list[idx][7]),\n",
        "                                            (centroid_data[2][0], centroid_data[2][1]), cv2.FONT_HERSHEY_SIMPLEX, 1, (np.average(centroid_data[1])/2), 0,\n",
        "                                            cv2.LINE_AA) \n",
        "                                \n",
        "                            if centroids_list[idx][4] == 0:\n",
        "                              centroids_list[idx][5] = \"unlocked\"\n",
        "                              centroids_list[idx][4] = 5\n",
        "                              centroids_list[idx][3] = 0\n",
        "                                \n",
        "                        if count - centroid_data[0] == 10:\n",
        "                            if sum(centroid_data[6]) / len(centroid_data[6]) != 0.0:\n",
        "                                with open(\"out1.csv\", \"a\") as o:\n",
        "                                    o.write(str(centroid_data[7]) + \": \" + str(sum(centroid_data[6]) / len(centroid_data[6])) + \"\\n\")\n",
        "                \n",
        "                    centroids_list = deque([car_data for car_data in list(centroids_list) if count - car_data[0] < 10])\n",
        "                    \n",
        "#                else:\n",
        "#                    break\n",
        "     \n",
        "    image[500:985 ,] =image2[500:985, ] ;image[1170:1600 ,] = image2[1170:1600 ,]\n",
        "\n",
        "    image = im.resize(image, 2000)\n",
        "    writer.write(image)\n",
        "    '''cv2.imshow('output', closing)\n",
        "    # Wait for Esc key to stop\n",
        "    if cv2.waitKey(33) == 27:\n",
        "        break '''\n",
        "    # outputs all the video frames into out folder present in the working directory\n",
        "    #cv2.imwrite(\"/content/drive/My Drive/Colab Notebooks/out/\" + str(count) + \".jpg\", image)\n",
        "    count += 1\n",
        "\n",
        "Time_Elapsed = time.time()-start\n",
        "print(\"Time Elapsed=\",Time_Elapsed,'s')\n",
        "print(\"finished Successfully\")\n",
        "print(image.shape)\n",
        "cap.release()\n",
        "writer.release()\n",
        "cv2.destroyAllWindows()\n",
        "# Output: https://drive.google.com/drive/folders/12HLHqqccQvQoCJFofr83Kava4-CcVcK3 \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO: Video Starting\n",
            "Video Open- True\n",
            "INFO: Tracking is in Progress...\n",
            "Time Elapsed= 2244.2843549251556 s\n",
            "finished Successfully\n",
            "(1093, 2000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hICZoFLugHLy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "bfbff964-0510-4fe2-bd7c-057e1a67c405"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Wed Jul 15 16:28:37 2020\n",
        "updated on July 15\n",
        "Re- updated on Aug 27\n",
        "@author: KGaurav\n",
        "Title : Align Drone Video Frames\n",
        "Directory: Work\n",
        "\"\"\"\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "sys.path.insert(0, os.path.abspath(\"/content/drive/My Drive/Colab Notebooks/\"))\n",
        "from align import alignImages\n",
        "\n",
        "# Path of dataset directory \n",
        "#path = \"E:\\CodeVideoData\\_DroneData\\ClipDroneData\\_1stDrone.MP4\"  # _1stDrone_2~2\n",
        "print(\"INFO: Video Starting\")\n",
        "#path = '/content/drive/My Drive/Colab Notebooks/Videos/3rdDrone.MP4'  \n",
        "#path = '/content/drive/My Drive/Colab Notebooks/Colab Notebooks/Videos/DJI_Morning.MP4' # 1stDrone DJI_Morning\n",
        "path = '/content/drive/My Drive/Colab Notebooks/Colab Notebooks Anshu/Videos/_2ndDrone_align.mp4'  # 1stDrone_newAlign_01\n",
        "cap = cv2.VideoCapture(path)  \n",
        "print(\"Video Status: \",cap.isOpened())\n",
        "\n",
        "#cv2.namedWindow(\"output\", cv2.WINDOW_NORMAL)\n",
        "frame_count = 0\n",
        "\n",
        "frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT ))\n",
        "#width = 1500; height = 820\n",
        "width = 4096; height = 2160\n",
        "#width = 4096; height = 432\n",
        "frate = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "#frate = 10\n",
        "#***************************************************************************************************************\n",
        "path21 = '/content/drive/My Drive/Colab Notebooks/Videos/_2ndDrone_NewAlign_01.mp4' # Video write\n",
        "writer = cv2.VideoWriter(path21, cv2.VideoWriter_fourcc(*'XVID'),frate, (width, height))\n",
        "first_frame = True\n",
        "print(\"INFO: Aligning is in Progress...\",frames)\n",
        "\n",
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "    frame_count += 1\n",
        "    if frame_count == 3620: # 10800,  3663\n",
        "      break\n",
        "    if first_frame:\n",
        "        imgRef = frame\n",
        "        first_frame = False\n",
        "    image = alignImages(frame , imgRef)\n",
        "    #result[0:864 ,] = frame[0:864, ] ;result[1296: ,] = frame[1296: ,]\n",
        "    #print(\"frame count = \",frame_count)\n",
        "    #cv2.imwrite(\"out/\" + str(frame_count) + \".jpg\",alignImage)\n",
        "    #cv2.imwrite(\"houghlines_result.jpg\",frame)\n",
        "    writer.write(image)\n",
        "\n",
        "  \n",
        "# destroy all the windows that is currently on \n",
        "print(\"Frame Size=\",image.shape)\n",
        "cap.release() \n",
        "writer.release()\n",
        "cv2.destroyAllWindows()  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO: Video Starting\n",
            "Video Status:  True\n",
            "INFO: Aligning is in Progress... 3659\n",
            "Frame Size= (2160, 4096, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLIgpM_hGhDI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "deba6e45-3709-49f6-8ffd-8adb15fac0f8"
      },
      "source": [
        "\"\"\"                                             \n",
        "Working CODE 1  : absdiff                                                             \n",
        "Usage: \n",
        "Updated!\n",
        "\"\"\"\n",
        "# Motion Detection realtime\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow # Colab cv2 imshow\n",
        "import numpy as np\n",
        "import imutils\n",
        "import datetime\n",
        "import time\n",
        "import random\n",
        "from collections import deque\n",
        "import imutils as im\n",
        "\n",
        "def main():\n",
        "    \n",
        "    w = 800\n",
        "    h = 600\n",
        "    def make_new_color():\n",
        "        return [random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)]\n",
        "\n",
        "    def rotate_image(image, angle):\n",
        "        image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "        rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "        result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "        result = result[:,50:4000]\n",
        "        result1 = result.copy()\n",
        "        result[:985 ,] = 0 ;result[1170: ,] = 0\n",
        "        return result, result1\n",
        "\n",
        "    # Sensor Details:\n",
        "    GSD = 0.0366 #3.66 cm/pixels\n",
        "    Iw = 4096; Sw = 13.2 # in mm\n",
        "    value = (GSD*Iw)/Sw\n",
        "    f = 8.8; distance = 100 # approximated, real distance = (R/r)*(f*W/w)\n",
        "    ratio = distance/f\n",
        "    count = 0\n",
        "       \n",
        "    path = '/content/drive/My Drive/Colab Notebooks/Videos/1stDrone.MP4'\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    width = 2936\n",
        "    height = 594\n",
        "    #frate = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "    cap.set(3, w)\n",
        "    cap.set(4, h)\n",
        "    \n",
        "#    print(cap.get(3))\n",
        "#    print(cap.get(4))\n",
        "    \n",
        "    if cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "    else:\n",
        "        ret = False\n",
        "    \n",
        "\n",
        "    frame_count = 0\n",
        "    print(\"[INFO] Vehicle detection is in progress...\")\n",
        "    centroids_list = deque([])\n",
        "    car_count = 0\n",
        "    with open(\"/content/drive/My Drive/Colab Notebooks/out2.csv\", \"w\") as o:\n",
        "      pass\n",
        "\n",
        "    #width = 4096, height = 2160\n",
        "    width = 1500; height = 820\n",
        "    #frate = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    frate = 10\n",
        "    #***************************************************************************************************************\n",
        "    path21 = '/content/drive/My Drive/Colab Notebooks/Videos/_Track_absdiff_06.mp4' # Video write\n",
        "    writer = cv2.VideoWriter(path21, cv2.VideoWriter_fourcc(*'XVID'),frate, (width, height))\n",
        "\n",
        "    start_frame = True\n",
        "    count_frame = 0\n",
        "    print(\"Start...\")\n",
        "    while ret:\n",
        "        if start_frame:\n",
        "            ret, frame1 = cap.read()\n",
        "            ret, frame2 = cap.read()\n",
        "            frame1, img = rotate_image(frame1, 1.78)\n",
        "            frame2, img2 = rotate_image(frame2, 1.78)\n",
        "            start_frame = False\n",
        "        else:\n",
        "            frame2, img = rotate_image(frame2, 1.78)\n",
        "            \n",
        "        count_frame += 1\n",
        "        if count_frame == 2000:  #3500\n",
        "          break\n",
        "        diff = cv2.absdiff(frame1, frame2)\n",
        "        grey = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
        "        blur = cv2.GaussianBlur(grey, (3, 3), 0)\n",
        "        #retvalbin, bins = cv2.threshold(blur, 10, 255, cv2.THRESH_BINARY)  #\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 3))  # kernel to apply to the morphology\n",
        "        closing = cv2.morphologyEx(blur, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
        "        \n",
        "        opening = cv2.morphologyEx(closing, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "        \n",
        "        dilation = cv2.dilate(opening, kernel, iterations=2) #adds pixels to the boundaries of objects in an image\n",
        "        closing = cv2.morphologyEx(dilation, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
        "        #eroded = cv2.erode(dilation, kernel, iterations=1 ) #removes pixels on object boundaries\n",
        "        #dilation = cv2.dilate(dilation, kernel)\n",
        "        \n",
        "        retvalbin, bins = cv2.threshold(dilation, 20, 255, cv2.THRESH_BINARY)  # removes the shadows\n",
        "        \n",
        "        # creates contours\n",
        "        # cv2.imshow('bins',bins)\n",
        "        contours, hierarchy = cv2.findContours(bins, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        minarea = 400\n",
        "        # max area for contours, can be quite large for buses\n",
        "        maxarea = 50000\n",
        "        # vectors for the x and y locations of contour centroids in current frame\n",
        "        cxx = np.zeros(len(contours))\n",
        "        cyy = np.zeros(len(contours))\n",
        "        \n",
        "        for i in range(len(contours)):  # cycles through all contours in current frame\n",
        "            if hierarchy[0, i, 3] == -1:  # using hierarchy to only count parent contours (contours not within others)\n",
        "                area = cv2.contourArea(contours[i])  # area of contour\n",
        "                if minarea < area < maxarea:  # area threshold for contour\n",
        "                    # calculating centroids of contours\n",
        "                    cnt = contours[i]\n",
        "                    M = cv2.moments(cnt)\n",
        "                    cx = int(M['m10'] / M['m00'])\n",
        "                    cy = int(M['m01'] / M['m00'])\n",
        "                    \n",
        "                    # gets bounding points of contour to create rectangle\n",
        "                    # x,y is top left corner and w,h is width and height\n",
        "                    x, y, w, h = cv2.boundingRect(cnt)\n",
        "                    \n",
        "                    xA = x\n",
        "                    xB = x + w\n",
        "                    yA = y\n",
        "                    yB = y + h\n",
        "\n",
        "                    if w  > 300 or w < 50:\n",
        "                        continue\n",
        "                    elif h < 20 or h > 90:\n",
        "                        continue\n",
        "                    elif w > 300 and h > 90:\n",
        "                        continue\n",
        "\n",
        "                    # Enumerate over all the cars in centroids_list\n",
        "                    #each centroid_list element contains: [last_updated_frame, color, position, \n",
        "                    #lock_count, unlock_count, lockstate(unlocked by default), list_of_car_speeds_in_prev_frames, id] \n",
        "                    not_matched = True\n",
        "                    for idx, centroid_data in enumerate(centroids_list):\n",
        "                        if centroid_data[0] == count:\n",
        "                            continue\n",
        "                        if centroids_list[idx][4] == 0:\n",
        "                            centroids_list[idx][5] = \"unlocked\"\n",
        "                            centroids_list[idx][4] = 5\n",
        "            \n",
        "                        # check proximity using manhattan distance\n",
        "                        X = abs(float(centroid_data[2][0] + centroid_data[2][2]) / 2 - float(xA + xB) / 2)\n",
        "                        Y = abs(float(centroid_data[2][1] + centroid_data[2][3]) / 2 - float(yA + yB) / 2)\n",
        "                        # if there is a rectangle in 10 pixel proximity of a rectangle of previous frame than i am assuming that,\n",
        "                        # the car in the rectangle is same as it was in the previous frame\n",
        "                        # 10 can be changed to any other value based on the movement happening in the frames, if vehicles are moving\n",
        "                        # more than 10 pixels per frame suppose 20 so change the value to 20\n",
        "                        if X < 35 and Y < 2:\n",
        "            \n",
        "                            not_matched = False\n",
        "                            centroids_list[idx][4] = 5\n",
        "                            centroids_list[idx][2] = [xA, yA, xB, yB]\n",
        "                            #*********************************************************************************************************\n",
        "                            #centroids_list[idx][6].append(np.sqrt(X ** 2 + Y ** 2) * 60*value*3.6/100/2)\n",
        "                            centroids_list[idx][6].append(np.sqrt(X ** 2 + Y ** 2) * 60*3.6*ratio/100/2)                            \n",
        "                            if centroids_list[idx][5] == \"unlocked\":\n",
        "            \n",
        "                                if centroids_list[idx][0] == count - 1:\n",
        "                                    centroids_list[idx][3] += 1\n",
        "            \n",
        "                                else:\n",
        "                                    centroids_list[idx][3] = 0\n",
        "            \n",
        "                            if centroids_list[idx][3] == 3:\n",
        "                                centroids_list[idx][5] = \"locked\"\n",
        "                                centroids_list[idx][3] = 0\n",
        "                            if centroids_list[idx][6][-1] != 0.0:\n",
        "                                cv2.rectangle(frame1, (xA, yA), (xB, yB), centroid_data[1], 2)\n",
        "                                cv2.putText(frame1, str(int(centroids_list[idx][6][-1]))+ str(\"KMPH\") + str(\",ID=\") + str(centroids_list[idx][7]),\n",
        "                                            (xA, yA), cv2.FONT_HERSHEY_SIMPLEX, 1, (np.average(centroid_data[1])/2), 1, cv2.LINE_AA) \n",
        "                                \n",
        "                            centroids_list[idx][0] = count\n",
        "                            break\n",
        "            \n",
        "            #    If rectangle not matches with previous rectangles that means it is a new car so make a new rectangle\n",
        "                    #if rectangle is not matching wiht previous rectangles ,then it is assumed that a new car has come and so new rectangle\n",
        "                    if not_matched:\n",
        "                        color = make_new_color()\n",
        "            \n",
        "                        # append new rectangle in previous cars list\n",
        "                        car_count = random.randint(1, 50)\n",
        "                        centroids_list.appendleft([count, color, (xA, yA, xB, yB), 1, 5, \"unlocked\", [0], car_count])\n",
        "                        #car_count += 1\n",
        "                        # cv2.rectangle(image, (xA, yA), (xB, yB), color, 2)\n",
        "                        # cv2.putText(image, \"0\",\n",
        "                        #             (xA, yA), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1, cv2.LINE_AA)\n",
        "                        prev_color = color\n",
        "                        prev_coords = [xA, yA, xB, yB]\n",
        "            \n",
        "                # plot all remaining locked rectangles\n",
        "                for idx, centroid_data in enumerate(centroids_list):\n",
        "            \n",
        "                    if centroid_data[5] == \"locked\" and centroid_data[0] != count:\n",
        "                        centroids_list[idx][4] -= 1\n",
        "                        if centroids_list[idx][6][-1] != 0.0:\n",
        "                            cv2.rectangle(frame1, (centroid_data[2][0], centroid_data[2][1]), (centroid_data[2][2], centroid_data[2][3]),\n",
        "                                          centroid_data[1], 2)\n",
        "                           # cv2.putText(image, str(centroids_list[idx][6][-1]),\n",
        "                            #            (centroid_data[2][0], centroid_data[2][1]), cv2.FONT_HERSHEY_SIMPLEX, 0.5, centroid_data[1], 1,\n",
        "                             #           cv2.LINE_AA)\n",
        "                            cv2.putText(frame1, str(int(centroids_list[idx][6][-1])) + str(\"KMPH\")  + str(\",ID=\") + str(centroids_list[idx][7]),\n",
        "                                        (centroid_data[2][0], centroid_data[2][1]), cv2.FONT_HERSHEY_SIMPLEX, 1, (np.average(centroid_data[1])/2), 1,\n",
        "                                        cv2.LINE_AA)  \n",
        "                            \n",
        "                        if centroids_list[idx][4] == 0:\n",
        "                            centroids_list[idx][5] = \"unlocked\"\n",
        "                            centroids_list[idx][4] = 5\n",
        "                            centroids_list[idx][3] = 0\n",
        "                            \n",
        "                    if count - centroid_data[0] == 10:\n",
        "                        if sum(centroid_data[6]) / len(centroid_data[6]) != 0.0:\n",
        "                            with open(\"out1.csv\", \"a\") as o:\n",
        "                                o.write(str(centroid_data[7]) + \": \" + str(sum(centroid_data[6]) / len(centroid_data[6])) + \"\\n\")\n",
        "            \n",
        "                centroids_list = deque([car_data for car_data in list(centroids_list) if count - car_data[0] < 10])\n",
        "                \n",
        "\n",
        "        frame1[500:985 ,] = img[500:985, ] ;frame1[1170:1600 ,] = img[1170:1600 ,]\n",
        "        frame1 = im.resize(frame1, 1500)\n",
        "        #print(frame1.shape)\n",
        "        \n",
        "        writer.write(frame1)\n",
        "        '''cv2.imshow('Output', frame1)\n",
        "        # Wait for Esc key to stop\n",
        "        if cv2.waitKey(33) == 27:\n",
        "            break '''\n",
        "        # outputs all the video frames into out folder present in the working directory\n",
        "        cv2.imwrite(\"E:/CodeVideoData/NewStitch2/out/\" + str(count) + \".jpg\", frame1)\n",
        "        count += 1\n",
        "        frame1 = frame2\n",
        "        ret, frame2 = cap.read()\n",
        "    \n",
        "\n",
        "    print(\"finished Successfully\")\n",
        "    \n",
        "    cap.release()\n",
        "    writer.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Start\")\n",
        "    start = time.time()\n",
        "    main()\n",
        "    print(\"Finished\")\n",
        "    Time_Elapsed = time.time()-start\n",
        "    print(\"Time Elapsed=\",Time_Elapsed,'s')\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start\n",
            "[INFO] Vehicle detection is in progress...\n",
            "Start...\n",
            "finished Successfully\n",
            "Finished\n",
            "Time Elapsed= 500.95209884643555 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZoIQuioLgxm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "cb151e7e-dec1-4b11-854f-2bdb893760d4"
      },
      "source": [
        "# Locations: /content/drive/My Drive/Colab Notebooks/\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Mon June 1 22:47:29 2020\n",
        "Updated on Mon July 15\n",
        "@author: Kumar Gaurav\n",
        "Institutions: EE, IIT Kanpur\n",
        "\n",
        "Title : Traffic Vehicle Speed Estimation\n",
        "------------------------------------------------------------------\n",
        "calculates speed of vehicles in realtime in KMPH\n",
        "\n",
        "key_formula =  ( speed in object plane / distance of camera from road ) = ( speed in image plane / focal length )\n",
        "approx fps of the video = 30\n",
        "\n",
        "to obtain accurate value distance to object (mm)  =   focal length (mm) * real height of the object (mm) * image height (pixels)\n",
        "                                                       ----------------------------------------------------------------\n",
        "                                                                 object height (pixels) * sensor height (mm)\n",
        "Default Code\n",
        "Updated 29 Jun 20\n",
        "\"\"\"\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow # Colab cv2 imshow\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import deque\n",
        "import imutils as im\n",
        "import time\n",
        "import sys\n",
        "sys.path.insert(0, \"/content/drive/My Drive/Colab Notebooks/\")\n",
        "from align import alignImages\n",
        "\n",
        "def make_new_color():\n",
        "    return [random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)]\n",
        "def make_new_veh():\n",
        "    return [random.randint(1, 200)]\n",
        "def rotate_image(image, angle):\n",
        "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "    result = result[:,50:4000]\n",
        "    result1 = result.copy()\n",
        "    #result[:985 ,] = 0 ;result[1170: ,] = 0\n",
        "    result[:970 ,] = 0 ;result[1200: ,] = 0\n",
        "    return result, result1\n",
        "\n",
        "def shadow_removal(img):\n",
        "    rgb_planes = cv2.split(img)\n",
        "    \n",
        "    result_planes = []\n",
        "    result_norm_planes = []\n",
        "    for plane in rgb_planes:\n",
        "        dilated_img = cv2.dilate(plane, np.ones((5,5), np.uint8))\n",
        "        bg_img = cv2.medianBlur(dilated_img, 21)\n",
        "        diff_img = 255 - cv2.absdiff(plane, bg_img)\n",
        "        norm_img = cv2.normalize(diff_img,None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
        "        result_planes.append(diff_img)\n",
        "        result_norm_planes.append(norm_img)\n",
        "    \n",
        "    result = cv2.merge(result_planes)\n",
        "    result_norm = cv2.merge(result_norm_planes)\n",
        "    return result_norm\n",
        "def canny_edge_detector(image): \n",
        "      \n",
        "    # Convert the image color to grayscale \n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)  \n",
        "      \n",
        "    # Reduce noise from the image \n",
        "    blur = cv2.GaussianBlur(gray_image, (5, 5), 0)  \n",
        "    canny = cv2.Canny(blur, 50, 150) \n",
        "    return canny \n",
        "def region_of_interest(image): \n",
        "    #height = image.shape[0] \n",
        "    '''polygons = np.array([ \n",
        "        [(200, height), (1100, height), (550, 250)]   # (width, height)\n",
        "        ]) '''\n",
        "    #polygons = np.array([[ (0, 900), (0,1250), (image.shape[1],1250), (image.shape[1], 900) ]])\n",
        "    #polygons = np.array([[ (0, 1030), (0,1150), (image.shape[1],1150), (image.shape[1], 1030) ]])\n",
        "    polygons = np.array([[ (0, 1100), (0,1230), (image.shape[1],1230), (image.shape[1], 1100) ]])\n",
        "    mask = np.zeros_like(image) \n",
        "    # Fill poly-function deals with multiple polygon \n",
        "    cv2.fillPoly(mask, polygons, 255)  \n",
        "      \n",
        "    # Bitwise operation between canny image and mask image \n",
        "    masked_image = cv2.bitwise_and(image, mask)  \n",
        "    return masked_image\n",
        "def getTransform(image, ty):\n",
        "    rows,cols = image.shape[:2]\n",
        "    #pts1 = np.float32([[50,50],[200,50],[50,200]])\n",
        "    #pts2 = np.float32([[10,100],[200,50],[100,250]])\n",
        "    #M = cv2.getAffineTransform(pts1,pts2)\n",
        "    ty = ty - cols\n",
        "    M = np.float32([[1,0,0],[0,1,ty]])\n",
        "    dst = cv2.warpAffine(image,M,(cols,rows))\n",
        "    return dst\n",
        "\n",
        "# Sensor Details:\n",
        "GSD = 0.0366 #3.66 cm/pixels\n",
        "Iw = 4096; Sw = 13.2 # in mm\n",
        "value = (GSD*Iw)/Sw\n",
        "f = 8.8; distance = 100 # approximated, real distance = (R/r)*(f*W/w)\n",
        "ratio = distance/f\n",
        "count = 0\n",
        "\n",
        "#/content/drive/My Drive/Colab Notebooks/Videos/1stDrone.MP4\n",
        "# capt.Video frames from a video\n",
        "print(\"INFO: Video Starting\")\n",
        "path = '/content/drive/My Drive/Colab Notebooks/Videos/DJI_Morning.MP4'  # 1stDrone DJI_Morning\n",
        "cap = cv2.VideoCapture(path)\n",
        "\n",
        "print(\"Video Open-\",cap.isOpened())\n",
        "# Subtractors\n",
        "sub = cv2.createBackgroundSubtractorMOG2()  # create background subtractor\n",
        "mogSubtractor = cv2.bgsegm.createBackgroundSubtractorMOG(300)\n",
        "mog2Subtractor = cv2.createBackgroundSubtractorMOG2() \n",
        "gmgSubtractor = cv2.bgsegm.createBackgroundSubtractorGMG(10, .8)\n",
        "knnSubtractor = cv2.createBackgroundSubtractorKNN()   #Very efficient if number of foreground pixels is low\n",
        "cntSubtractor = cv2.bgsegm.createBackgroundSubtractorCNT(5, True)\n",
        "es = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (20,12))\n",
        "\n",
        "centroids_list = deque([])\n",
        "car_count = 0\n",
        "'''with open(\"/content/drive/My Drive/Colab Notebooks/out1.csv\", \"w\") as o:\n",
        "    pass'''\n",
        "\n",
        "#width = 1500 ; height = 820\n",
        "width = 2000; height = 1093\n",
        "#frate = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "frate = 20\n",
        "#***************************************************************************************************************\n",
        "path21 = '/content/drive/My Drive/Colab Notebooks/Videos/_Track_KNN_align_04.mp4' # Video write\n",
        "writer = cv2.VideoWriter(path21, cv2.VideoWriter_fourcc(*'XVID'),frate, (width, height))\n",
        "\n",
        "print(\"INFO: Tracking is in Progress...\")\n",
        "frame_count = 0\n",
        "start = time.time()\n",
        "dist_dict = {}\n",
        "first_frame = True\n",
        "while True:\n",
        "\n",
        "    ret, frame = cap.read()  # import image\n",
        "    frame_count +=  1\n",
        "    if frame_count == 5: # 3600\n",
        "      break\n",
        "\n",
        "    if  ret:  # if there is a frame continue with code\n",
        "        if first_frame:\n",
        "            imgRef = frame\n",
        "            first_frame = False\n",
        "\n",
        "        frame = alignImages(frame, imgRef)\n",
        "        image, image2 = rotate_image(frame, 1.58)\n",
        "        '''\n",
        "        cropped_image = region_of_interest(image)\n",
        "        canny_image = canny_edge_detector(cropped_image)\n",
        "        minLineLength = 100\n",
        "        maxLineGap = 50\n",
        "        lines = cv2.HoughLinesP(canny_image,1,np.pi/180,100,minLineLength,maxLineGap)\n",
        "        for x1,y1,x2,y2 in lines[0]:\n",
        "            #cv2.line(image,(x1,y1),(x2,y2),(0,0,255),2)\n",
        "            dist_dict[(x1,x2)] = (y1,y2)\n",
        "        image1 = getTransform(image, y2) \n",
        "        #image = shadow_removal(image)\n",
        "        #canny_image = canny_edge_detector(image1)\n",
        "        '''\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # converts image to gray\n",
        "        fg_mask = knnSubtractor.apply(gray)  #  mog2Subtractor  knnSubtractor\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
        "        value1, th = cv2.threshold(fg_mask, 5, 255, cv2.THRESH_BINARY)\n",
        "        opening = cv2.morphologyEx(th, cv2.MORPH_OPEN, kernel, iterations=1) #erosion followed by dilation, useful in removing noises\n",
        "        closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel, iterations=3) #Dilation followed by Erosion\n",
        "        dilation = cv2.dilate(closing, kernel, iterations = 1)\n",
        "        '''        \n",
        "        dilation = cv2.dilate(opening, kernel, iterations=2) #adds pixels to the boundaries of objects in an image\n",
        "        #eroded = cv2.erode(dilation, kernel, iterations=1 ) #removes pixels on object boundaries        \n",
        "        '''\n",
        "        contours, hierarchy = cv2.findContours(dilation, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        minarea = 700\n",
        "        # max area for contours, can be quite large for buses\n",
        "        maxarea = 19000\n",
        "        # vectors for the x and y locations of contour centroids in current frame\n",
        "        '''cxx = np.zeros(len(contours))\n",
        "        cyy = np.zeros(len(contours))\n",
        "        '''\n",
        "        for i in range(len(contours)):  # cycles through all contours in current frame\n",
        "            if hierarchy[0, i, 3] == -1:  # using hierarchy to only count parent contours (contours not within others)\n",
        "                area = cv2.contourArea(contours[i])  # area of contour\n",
        "                if minarea < area < maxarea:  # area threshold for contour\n",
        "                    # calculating centroids of contours\n",
        "                    cnt = contours[i]\n",
        "                    M = cv2.moments(cnt)\n",
        "                    cx = int(M['m10'] / M['m00'])\n",
        "                    cy = int(M['m01'] / M['m00'])\n",
        "                    \n",
        "                    x, y, w, h = cv2.boundingRect(cnt)\n",
        "                    \n",
        "                    xA = x\n",
        "                    xB = x + w\n",
        "                    yA = y\n",
        "                    yB = y + h\n",
        "                    if w  > 300 or w < 50 or h < 22 or h > 90:\n",
        "                        continue\n",
        "                    if w > 300 and h > 90:\n",
        "                        continue\n",
        "                        \n",
        "                    not_matched = True\n",
        "                    for idx, centroid_data in enumerate(centroids_list):\n",
        "                        if centroid_data[0] == count:\n",
        "                            continue\n",
        "                        if centroids_list[idx][4] == 0:\n",
        "                            centroids_list[idx][5] = \"unlocked\"\n",
        "                            centroids_list[idx][4] = 5\n",
        "            \n",
        "                        # check proximity using manhattan distance\n",
        "                        X = abs(float(centroid_data[2][0] + centroid_data[2][2]) / 2 - float(xA + xB) / 2)\n",
        "                        Y = abs(float(centroid_data[2][1] + centroid_data[2][3]) / 2 - float(yA + yB) / 2)\n",
        "\n",
        "                        if X < 50 and Y < 15:\n",
        "                            if h < 40 and X < 35:            \n",
        "                                not_matched = False\n",
        "                                centroids_list[idx][4] = 5\n",
        "                                centroids_list[idx][2] = [xA, yA, xB, yB]\n",
        "                                #*********************************************************************************************************\n",
        "                                #centroids_list[idx][6].append(np.sqrt(X ** 2 + Y ** 2) * 60*value*3.6/100/2)\n",
        "                                centroids_list[idx][6].append(np.sqrt(X ** 2 + Y ** 2) * 60*3.6*ratio/100/2)\n",
        "                                if centroids_list[idx][5] == \"unlocked\":\n",
        "                \n",
        "                                    if centroids_list[idx][0] == count - 1:\n",
        "                                        centroids_list[idx][3] += 1\n",
        "                \n",
        "                                    else:\n",
        "                                        centroids_list[idx][3] = 0\n",
        "                \n",
        "                                if centroids_list[idx][3] == 3:\n",
        "                                    centroids_list[idx][5] = \"locked\"\n",
        "                                    centroids_list[idx][3] = 0\n",
        "                                if centroids_list[idx][6][-1] != 0.0:\n",
        "                                    cv2.rectangle(image, (xA, yA), (xB, yB), centroid_data[1], 2)\n",
        "                                    cv2.putText(image, str(int(centroids_list[idx][6][-1]))+ str(\"KMPH\") + str(\",ID=\") + str(centroids_list[idx][7]),\n",
        "                                                (xA, yA), cv2.FONT_HERSHEY_SIMPLEX, 1, (np.average(centroid_data[1])/2), 1, cv2.LINE_AA) \n",
        "                                    cv2.putText(image, str(\"bike\"),(centroid_data[2][0]+100, centroid_data[2][1]+20) ,\n",
        "                                                cv2.FONT_HERSHEY_SIMPLEX, 1, (255,20,147), 2, cv2.LINE_AA)\n",
        "                            elif h > 40 and w > 185:          \n",
        "                                not_matched = False\n",
        "                                centroids_list[idx][4] = 5\n",
        "                                centroids_list[idx][2] = [xA, yA, xB, yB]\n",
        "                                #*********************************************************************************************************\n",
        "                                #centroids_list[idx][6].append(np.sqrt(X ** 2 + Y ** 2) * 60*value*3.6/100/2)\n",
        "                                centroids_list[idx][6].append(np.sqrt(X ** 2 + Y ** 2) * 60*3.6*ratio/100/2)\n",
        "                                #if cx < 300 and cx > 3700:\n",
        "                                if centroids_list[idx][5] == \"unlocked\":\n",
        "                \n",
        "                                    if centroids_list[idx][0] == count - 1:\n",
        "                                        centroids_list[idx][3] += 1\n",
        "                \n",
        "                                    else:\n",
        "                                        centroids_list[idx][3] = 0\n",
        "            \n",
        "                                #if cx > 300 and cx < 3700:\n",
        "                                if centroids_list[idx][3] == 3:\n",
        "                                    centroids_list[idx][5] = \"locked\"\n",
        "                                    centroids_list[idx][3] = 0\n",
        "                                if centroids_list[idx][6][-1] != 0.0:\n",
        "                                    cv2.rectangle(image, (xA, yA), (xB, yB), centroid_data[1], 2)\n",
        "                                    cv2.putText(image, str(int(centroids_list[idx][6][-1]))+ str(\"KMPH\") + str(\",ID=\") + str(centroids_list[idx][7]),\n",
        "                                                (xA, yA), cv2.FONT_HERSHEY_SIMPLEX, 1, (np.average(centroid_data[1])/2), 1, cv2.LINE_AA) \n",
        "                                    cv2.putText(image, str(\"Bus\"), (centroid_data[2][0], centroid_data[2][1]+40),\n",
        "                                                cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,20,147), 2, cv2.LINE_AA)\n",
        "                            else:          \n",
        "                                not_matched = False\n",
        "                                centroids_list[idx][4] = 5\n",
        "                                centroids_list[idx][2] = [xA, yA, xB, yB]\n",
        "                                #*********************************************************************************************************\n",
        "                                #centroids_list[idx][6].append(np.sqrt(X ** 2 + Y ** 2) * 60*value*3.6/100/2)\n",
        "                                centroids_list[idx][6].append(np.sqrt(X ** 2 + Y ** 2) * 60*3.6*ratio/100/2)\n",
        "                                if centroids_list[idx][5] == \"unlocked\":\n",
        "                \n",
        "                                    if centroids_list[idx][0] == count - 1:\n",
        "                                        centroids_list[idx][3] += 1\n",
        "                \n",
        "                                    else:\n",
        "                                        centroids_list[idx][3] = 0\n",
        "                \n",
        "                                if centroids_list[idx][3] == 3:\n",
        "                                    centroids_list[idx][5] = \"locked\"\n",
        "                                    centroids_list[idx][3] = 0\n",
        "                                if centroids_list[idx][6][-1] != 0.0:\n",
        "                                    cv2.rectangle(image, (xA, yA), (xB, yB), centroid_data[1], 2)\n",
        "                                    cv2.putText(image, str(int(centroids_list[idx][6][-1]))+ str(\"KMPH\") + str(\",ID=\") + str(centroids_list[idx][7]),\n",
        "                                                (xA, yA), cv2.FONT_HERSHEY_SIMPLEX, 1, (np.average(centroid_data[1])/2), 1, cv2.LINE_AA) \n",
        "                                    cv2.putText(image, str(\"Car\"), (centroid_data[2][0], centroid_data[2][1]+40), \n",
        "                                                cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,20,147), 2, cv2.LINE_AA)\n",
        "                                \n",
        "                            centroids_list[idx][0] = count\n",
        "                            break\n",
        "            \n",
        "                    if not_matched:\n",
        "                        color = make_new_color()\n",
        "            \n",
        "                        # append new rectangle in previous cars list\n",
        "                        car_count = random.randint(1, 40) \n",
        "                        centroids_list.appendleft([count, color, (xA, yA, xB, yB), 1, 5, \"unlocked\", [0], car_count])\n",
        "                        #car_count += 1\n",
        "                        # cv2.rectangle(image, (xA, yA), (xB, yB), color, 2)\n",
        "                        # cv2.putText(image, \"0\",\n",
        "                        #             (xA, yA), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1, cv2.LINE_AA)\n",
        "                        prev_color = color\n",
        "                        prev_coords = [xA, yA, xB, yB]\n",
        "            \n",
        "                    # plot all remaining locked rectangles\n",
        "                    for idx, centroid_data in enumerate(centroids_list):\n",
        "                \n",
        "                        if centroid_data[5] == \"locked\" and centroid_data[0] != count:\n",
        "                            centroids_list[idx][4] -= 1\n",
        "                            if centroids_list[idx][6][-1] != 0.0:\n",
        "                                cv2.rectangle(image, (centroid_data[2][0], centroid_data[2][1]), (centroid_data[2][2], centroid_data[2][3]),\n",
        "                                              centroid_data[1], 2)\n",
        "\n",
        "                                cv2.putText(image, str(int(centroids_list[idx][6][-1])) + str(\"KMPH\") + str(\",ID=\") + str(centroids_list[idx][7]),\n",
        "                                            (centroid_data[2][0], centroid_data[2][1]), cv2.FONT_HERSHEY_SIMPLEX, 1, (np.average(centroid_data[1])/2), 1, cv2.LINE_AA) \n",
        "                                \n",
        "                            if centroids_list[idx][4] == 0:\n",
        "                              centroids_list[idx][5] = \"unlocked\"\n",
        "                              centroids_list[idx][4] = 5\n",
        "                              centroids_list[idx][3] = 0\n",
        "                                \n",
        "                        \n",
        "                    centroids_list = deque([car_data for car_data in list(centroids_list) if count - car_data[0] < 20])\n",
        "                    \n",
        "     \n",
        "    image[500:970 ,] = image2[500:970, ] ;image[1200:1600 ,] = image2[1200:1600 ,]\n",
        "\n",
        "    image = im.resize(image, 2000)\n",
        "    writer.write(image)\n",
        "    '''cv2.imshow('output', closing)\n",
        "    # Wait for Esc key to stop\n",
        "    if cv2.waitKey(33) == 27:\n",
        "        break '''\n",
        "    # outputs all the video frames into out folder present in the working directory\n",
        "    #cv2.imwrite(\"/content/drive/My Drive/Colab Notebooks/out/\" + str(count) + \".jpg\", image)\n",
        "    count += 1\n",
        "\n",
        "Time_Elapsed = time.time()-start\n",
        "print(\"Time Elapsed=\",Time_Elapsed,'s')\n",
        "print(\"finished Successfully\")\n",
        "print(image.shape)\n",
        "cap.release()\n",
        "writer.release()\n",
        "cv2.destroyAllWindows()\n",
        "# Output: https://drive.google.com/drive/folders/12HLHqqccQvQoCJFofr83Kava4-CcVcK3 \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-3b02acd708cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/drive/My Drive/Colab Notebooks/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0malign\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0malignImages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_new_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'align'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSWV0Eo7gz5A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "2b72fa6c-385d-461f-92e2-b2a3d1846cc6"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"/content/drive/My Drive/Colab Notebooks/\")\n",
        "from align import alignImages"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-3b719c8ceb1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/drive/My Drive/Colab Notebooks/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0malign\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0malignImages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'align'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey3-B-KSnRLn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "7a6330af-6c5f-4af3-9c4c-ada74f87d9c0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7CQ20uEUlpp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "9c7e83ee-3031-4026-fc6e-942abb417619"
      },
      "source": [
        "# Locations: /content/drive/My Drive/Colab Notebooks/\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Mon June 1 22:47:29 2020\n",
        "Updated on Mon June 12\n",
        "@author: Kumar Gaurav\n",
        "Institutions: EE, IIT Kanpur\n",
        "\n",
        "Title : Traffic Vehicle Speed Estimation\n",
        "------------------------------------------------------------------\n",
        "calculates speed of vehicles in realtime in KMPH\n",
        "\n",
        "key_formula =  ( speed in object plane / distance of camera from road ) = ( speed in image plane / focal length )\n",
        "approx fps of the video = 30\n",
        "\n",
        "to obtain accurate value distance to object (mm)  =   focal length (mm) * real height of the object (mm) * image height (pixels)\n",
        "                                                       ----------------------------------------------------------------\n",
        "                                                                 object height (pixels) * sensor height (mm)\n",
        "Default Code\n",
        "Updated 29 Jun 20\n",
        "\"\"\"\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow # Colab cv2 imshow\n",
        "import numpy as np\n",
        "import random\n",
        "from collections import deque\n",
        "import imutils as im\n",
        "import time\n",
        "\n",
        "\n",
        "def make_new_color():\n",
        "    return [random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)]\n",
        "def make_new_veh():\n",
        "    return [random.randint(1, 50)]\n",
        "def rotate_image(image, angle):\n",
        "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "    result = result[:,50:4000]\n",
        "    result1 = result.copy()\n",
        "    result[:985 ,] = 0 ;result[1170: ,] = 0\n",
        "    return result, result1\n",
        "def shadow_removal(img):\n",
        "    rgb_planes = cv2.split(img)\n",
        "    \n",
        "    result_planes = []\n",
        "    result_norm_planes = []\n",
        "    for plane in rgb_planes:\n",
        "        dilated_img = cv2.dilate(plane, np.ones((5,5), np.uint8))\n",
        "        bg_img = cv2.medianBlur(dilated_img, 21)\n",
        "        diff_img = 255 - cv2.absdiff(plane, bg_img)\n",
        "        norm_img = cv2.normalize(diff_img,None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
        "        result_planes.append(diff_img)\n",
        "        result_norm_planes.append(norm_img)\n",
        "    \n",
        "    result = cv2.merge(result_planes)\n",
        "    result_norm = cv2.merge(result_norm_planes)\n",
        "    return result_norm\n",
        "\n",
        "# Sensor Details:\n",
        "GSD = 0.0366 #3.66 cm/pixels\n",
        "Iw = 4096; Sw = 13.2 # in mm\n",
        "value = (GSD*Iw)/Sw\n",
        "f = 8.8; distance = 100 # approximated, real distance = (R/r)*(f*W/w)\n",
        "ratio = distance/f\n",
        "count = 0\n",
        "\n",
        "#/content/drive/My Drive/Colab Notebooks/Videos/1stDrone.MP4\n",
        "# capt.Video frames from a video\n",
        "print(\"INFO: Video Starting\")\n",
        "path = '/content/drive/My Drive/Colab Notebooks/Videos/1stDrone.MP4'\n",
        "cap = cv2.VideoCapture(path)\n",
        "\n",
        "print(\"Video Open-\",cap.isOpened())\n",
        "# Subtractors\n",
        "sub = cv2.createBackgroundSubtractorMOG2()  # create background subtractor\n",
        "mogSubtractor = cv2.bgsegm.createBackgroundSubtractorMOG(300)\n",
        "mog2Subtractor = cv2.createBackgroundSubtractorMOG2() \n",
        "gmgSubtractor = cv2.bgsegm.createBackgroundSubtractorGMG(10, .8)\n",
        "knnSubtractor = cv2.createBackgroundSubtractorKNN()   #Very efficient if number of foreground pixels is low\n",
        "cntSubtractor = cv2.bgsegm.createBackgroundSubtractorCNT(5, True)\n",
        "es = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (20,12))\n",
        "\n",
        "centroids_list = deque([])\n",
        "car_count = 0\n",
        "'''with open(\"/content/drive/My Drive/Colab Notebooks/out1.csv\", \"w\") as o:\n",
        "    pass'''\n",
        "\n",
        "#width = 1500 ; height = 820\n",
        "width = 2000; height = 1093\n",
        "#frate = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "frate = 10\n",
        "#***************************************************************************************************************\n",
        "path21 = '/content/drive/My Drive/Colab Notebooks/Videos/_Track_KNN_final4.mp4' # Video write\n",
        "writer = cv2.VideoWriter(path21, cv2.VideoWriter_fourcc(*'XVID'),frate, (width, height))\n",
        "\n",
        "print(\"INFO: Tracking is in Progress...\")\n",
        "frame_count = 0\n",
        "start = time.time()\n",
        "\n",
        "while True:\n",
        "\n",
        "    ret, frame = cap.read()  # import image\n",
        "    frame_count +=  1\n",
        "    if frame_count == 3600:\n",
        "      break\n",
        "\n",
        "\n",
        "    if  ret:  # if there is a frame continue with code\n",
        "        image, image2 = rotate_image(frame, 1.78)\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # converts image to gray\n",
        "        #image1 = shadow_removal(gray)\n",
        "        fg_mask = knnSubtractor.apply(gray)  #  mog2Subtractor  knnSubtractor\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
        "        value, th = cv2.threshold(fg_mask, 10, 255, cv2.THRESH_BINARY)\n",
        "        opening = cv2.morphologyEx(th, cv2.MORPH_OPEN, kernel, iterations=1) #erosion followed by dilation, useful in removing noises\n",
        "        closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel, iterations=3) #Dilation followed by Erosion\n",
        "        dilation = cv2.dilate(closing, kernel, iterations = 1)\n",
        "        '''        \n",
        "        dilation = cv2.dilate(opening, kernel, iterations=2) #adds pixels to the boundaries of objects in an image\n",
        "        #eroded = cv2.erode(dilation, kernel, iterations=1 ) #removes pixels on object boundaries        \n",
        "        '''\n",
        "        contours, hierarchy = cv2.findContours(dilation, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        minarea = 700\n",
        "        # max area for contours, can be quite large for buses\n",
        "        maxarea = 18000\n",
        "        # vectors for the x and y locations of contour centroids in current frame\n",
        "        '''cxx = np.zeros(len(contours))\n",
        "        cyy = np.zeros(len(contours))\n",
        "        '''\n",
        "        for i in range(len(contours)):  # cycles through all contours in current frame\n",
        "            if hierarchy[0, i, 3] == -1:  # using hierarchy to only count parent contours (contours not within others)\n",
        "                area = cv2.contourArea(contours[i])  # area of contour\n",
        "                if minarea < area < maxarea:  # area threshold for contour\n",
        "                    # calculating centroids of contours\n",
        "                    cnt = contours[i]\n",
        "                    M = cv2.moments(cnt)\n",
        "                    cx = int(M['m10'] / M['m00'])\n",
        "                    cy = int(M['m01'] / M['m00'])\n",
        "                    \n",
        "                    x, y, w, h = cv2.boundingRect(cnt)\n",
        "                    \n",
        "                    xA = x\n",
        "                    xB = x + w\n",
        "                    yA = y\n",
        "                    yB = y + h\n",
        "                    if w  > 300 or w < 50:\n",
        "                        continue\n",
        "                    elif h < 20 or h > 90:\n",
        "                        continue\n",
        "                    elif w > 300 and h > 90:\n",
        "                        continue\n",
        "                        \n",
        "                    not_matched = True\n",
        "                    for idx, centroid_data in enumerate(centroids_list):\n",
        "                        if centroid_data[0] == count:\n",
        "                            continue\n",
        "                        if centroids_list[idx][4] == 0:\n",
        "                            centroids_list[idx][5] = \"unlocked\"\n",
        "                            centroids_list[idx][4] = 5\n",
        "            \n",
        "                        # check proximity using manhattan distance\n",
        "                        X = abs(float(centroid_data[2][0] + centroid_data[2][2]) / 2 - float(xA + xB) / 2)\n",
        "                        Y = abs(float(centroid_data[2][1] + centroid_data[2][3]) / 2 - float(yA + yB) / 2)\n",
        "\n",
        "                        if X < 50 and Y < 3:\n",
        "                            if h < 40 and X < 35:            \n",
        "                                not_matched = False\n",
        "                                centroids_list[idx][4] = 5\n",
        "                                centroids_list[idx][2] = [xA, yA, xB, yB]\n",
        "                                #*********************************************************************************************************\n",
        "                                #centroids_list[idx][6].append(np.sqrt(X ** 2 + Y ** 2) * 60*value*3.6/100/2)\n",
        "                                centroids_list[idx][6].append(np.sqrt(X ** 2 + Y ** 2) * 60*3.6*ratio/100/2)\n",
        "                                if centroids_list[idx][5] == \"unlocked\":\n",
        "                \n",
        "                                    if centroids_list[idx][0] == count - 1:\n",
        "                                        centroids_list[idx][3] += 1\n",
        "                \n",
        "                                    else:\n",
        "                                        centroids_list[idx][3] = 0\n",
        "                \n",
        "                                if centroids_list[idx][3] == 3:\n",
        "                                    centroids_list[idx][5] = \"locked\"\n",
        "                                    centroids_list[idx][3] = 0\n",
        "                                if centroids_list[idx][6][-1] != 0.0:\n",
        "                                    cv2.rectangle(image, (xA, yA), (xB, yB), centroid_data[1], 2)\n",
        "                                    cv2.putText(image, str(int(centroids_list[idx][6][-1]))+ str(\"KMPH\") + str(\",ID=\") + str(centroids_list[idx][7]),\n",
        "                                                (xA, yA), cv2.FONT_HERSHEY_SIMPLEX, 1, (np.average(centroid_data[1])/2), 1, cv2.LINE_AA) \n",
        "                                    cv2.putText(image, str(\"bike\"),(centroid_data[2][0]+100, centroid_data[2][1]+20) ,\n",
        "                                                cv2.FONT_HERSHEY_SIMPLEX, 1, (255,20,147), 2, cv2.LINE_AA)\n",
        "                            elif h > 40 and w > 200:          \n",
        "                                not_matched = False\n",
        "                                centroids_list[idx][4] = 5\n",
        "                                centroids_list[idx][2] = [xA, yA, xB, yB]\n",
        "                                #*********************************************************************************************************\n",
        "                                #centroids_list[idx][6].append(np.sqrt(X ** 2 + Y ** 2) * 60*value*3.6/100/2)\n",
        "                                centroids_list[idx][6].append(np.sqrt(X ** 2 + Y ** 2) * 60*3.6*ratio/100/2)\n",
        "                                #if cx < 300 and cx > 3700:\n",
        "                                if centroids_list[idx][5] == \"unlocked\":\n",
        "                \n",
        "                                    if centroids_list[idx][0] == count - 1:\n",
        "                                        centroids_list[idx][3] += 1\n",
        "                \n",
        "                                    else:\n",
        "                                        centroids_list[idx][3] = 0\n",
        "            \n",
        "                                #if cx > 300 and cx < 3700:\n",
        "                                if centroids_list[idx][3] == 3:\n",
        "                                    centroids_list[idx][5] = \"locked\"\n",
        "                                    centroids_list[idx][3] = 0\n",
        "                                if centroids_list[idx][6][-1] != 0.0:\n",
        "                                    cv2.rectangle(image, (xA, yA), (xB, yB), centroid_data[1], 2)\n",
        "                                    cv2.putText(image, str(int(centroids_list[idx][6][-1]))+ str(\"KMPH\") + str(\",ID=\") + str(centroids_list[idx][7]),\n",
        "                                                (xA, yA), cv2.FONT_HERSHEY_SIMPLEX, 1, (np.average(centroid_data[1])/2), 1, cv2.LINE_AA) \n",
        "                                    cv2.putText(image, str(\"Bus\"), (centroid_data[2][0], centroid_data[2][1]+40),\n",
        "                                                cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,20,147), 2, cv2.LINE_AA)\n",
        "                            else:          \n",
        "                                not_matched = False\n",
        "                                centroids_list[idx][4] = 5\n",
        "                                centroids_list[idx][2] = [xA, yA, xB, yB]\n",
        "                                #*********************************************************************************************************\n",
        "                                #centroids_list[idx][6].append(np.sqrt(X ** 2 + Y ** 2) * 60*value*3.6/100/2)\n",
        "                                centroids_list[idx][6].append(np.sqrt(X ** 2 + Y ** 2) * 60*3.6*ratio/100/2)\n",
        "                                if centroids_list[idx][5] == \"unlocked\":\n",
        "                \n",
        "                                    if centroids_list[idx][0] == count - 1:\n",
        "                                        centroids_list[idx][3] += 1\n",
        "                \n",
        "                                    else:\n",
        "                                        centroids_list[idx][3] = 0\n",
        "                \n",
        "                                if centroids_list[idx][3] == 3:\n",
        "                                    centroids_list[idx][5] = \"locked\"\n",
        "                                    centroids_list[idx][3] = 0\n",
        "                                if centroids_list[idx][6][-1] != 0.0:\n",
        "                                    cv2.rectangle(image, (xA, yA), (xB, yB), centroid_data[1], 2)\n",
        "                                    cv2.putText(image, str(int(centroids_list[idx][6][-1]))+ str(\"KMPH\") + str(\",ID=\") + str(centroids_list[idx][7]),\n",
        "                                                (xA, yA), cv2.FONT_HERSHEY_SIMPLEX, 1, (np.average(centroid_data[1])/2), 1, cv2.LINE_AA) \n",
        "                                    cv2.putText(image, str(\"Car\"), (centroid_data[2][0], centroid_data[2][1]+40), \n",
        "                                                cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,20,147), 2, cv2.LINE_AA)\n",
        "                                \n",
        "                            centroids_list[idx][0] = count\n",
        "                            break\n",
        "            \n",
        "                    if not_matched:\n",
        "                        color = make_new_color()\n",
        "            \n",
        "                        # append new rectangle in previous cars list\n",
        "                        car_count = random.randint(1, 40) \n",
        "                        centroids_list.appendleft([count, color, (xA, yA, xB, yB), 1, 5, \"unlocked\", [0], car_count])\n",
        "                        #car_count += 1\n",
        "                        # cv2.rectangle(image, (xA, yA), (xB, yB), color, 2)\n",
        "                        # cv2.putText(image, \"0\",\n",
        "                        #             (xA, yA), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1, cv2.LINE_AA)\n",
        "                        prev_color = color\n",
        "                        prev_coords = [xA, yA, xB, yB]\n",
        "            \n",
        "                    # plot all remaining locked rectangles\n",
        "                    for idx, centroid_data in enumerate(centroids_list):\n",
        "                \n",
        "                        if centroid_data[5] == \"locked\" and centroid_data[0] != count:\n",
        "                            centroids_list[idx][4] -= 1\n",
        "                            if centroids_list[idx][6][-1] != 0.0:\n",
        "                                cv2.rectangle(image, (centroid_data[2][0], centroid_data[2][1]), (centroid_data[2][2], centroid_data[2][3]),\n",
        "                                              centroid_data[1], 2)\n",
        "\n",
        "                                cv2.putText(image, str(int(centroids_list[idx][6][-1])) + str(\"KMPH\") + str(\",ID=\") + str(centroids_list[idx][7]),\n",
        "                                            (centroid_data[2][0], centroid_data[2][1]), cv2.FONT_HERSHEY_SIMPLEX, 1, (np.average(centroid_data[1])/2), 1, cv2.LINE_AA) \n",
        "                                \n",
        "                            if centroids_list[idx][4] == 0:\n",
        "                              centroids_list[idx][5] = \"unlocked\"\n",
        "                              centroids_list[idx][4] = 5\n",
        "                              centroids_list[idx][3] = 0\n",
        "                                \n",
        "                        if count - centroid_data[0] == 20:\n",
        "                            if sum(centroid_data[6]) / len(centroid_data[6]) != 0.0:\n",
        "                                with open(\"out1.csv\", \"a\") as o:\n",
        "                                    o.write(str(centroid_data[7]) + \": \" + str(sum(centroid_data[6]) / len(centroid_data[6])) + \"\\n\")\n",
        "                \n",
        "                    centroids_list = deque([car_data for car_data in list(centroids_list) if count - car_data[0] < 20])\n",
        "                    \n",
        "     \n",
        "    image[500:985 ,] =image2[500:985, ] ;image[1170:1600 ,] = image2[1170:1600 ,]\n",
        "\n",
        "    image = im.resize(image, 2000)\n",
        "    writer.write(image)\n",
        "    '''cv2.imshow('output', closing)\n",
        "    # Wait for Esc key to stop\n",
        "    if cv2.waitKey(33) == 27:\n",
        "        break '''\n",
        "    # outputs all the video frames into out folder present in the working directory\n",
        "    #cv2.imwrite(\"/content/drive/My Drive/Colab Notebooks/out/\" + str(count) + \".jpg\", image)\n",
        "    count += 1\n",
        "\n",
        "Time_Elapsed = time.time()-start\n",
        "print(\"Time Elapsed=\",Time_Elapsed,'s')\n",
        "print(\"finished Successfully\")\n",
        "print(image.shape)\n",
        "cap.release()\n",
        "writer.release()\n",
        "cv2.destroyAllWindows()\n",
        "# Output: https://drive.google.com/drive/folders/12HLHqqccQvQoCJFofr83Kava4-CcVcK3 \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO: Video Starting\n",
            "Video Open- False\n",
            "INFO: Tracking is in Progress...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e3674bff11e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m985\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mimage2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m985\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m;\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1170\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1600\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1170\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1600\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'image2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjRc-trGWz3u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "502549fd-a5a8-4b0e-c168-3a9d16f5362a"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sun Jul  5 07:42:04 2020\n",
        "updated on July 12\n",
        "@author: KGaurav\n",
        "Title: Real Time Road Lane Detection [with image alignment]\n",
        "minLineLength = 100\n",
        "maxLineGap = 140\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import sympy as sy\n",
        "import sys\n",
        "sys.path.insert(0, \"/content/drive/My Drive/Colab Notebooks/\")\n",
        "from linearRegresion import regression\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "def clipVideo(image):\n",
        "    img = np.zeros(image.shape, np.uint8)\n",
        "    img2 = None\n",
        "    #We could have used fixed numbers as the vertices of the polygon,\n",
        "    #but they will not be applicable to images with different dimesnions.\n",
        "    rows, cols = image.shape[:2] # (hight, width)\n",
        "    h1 = 864; h2 = 1296\n",
        "\n",
        "    img[h1:h2, ] = image[h1:h2, ] # image[height_range, width_range]\n",
        "    #print(img.shape)\n",
        "    return img, img2\n",
        "\n",
        "def RGB_color_selection(image):\n",
        "\n",
        "    #White color mask\n",
        "    lower_threshold = np.uint8([200, 200, 200])\n",
        "    upper_threshold = np.uint8([255, 255, 255])\n",
        "    white_mask = cv2.inRange(image, lower_threshold, upper_threshold)\n",
        "    \n",
        "    masked_image = cv2.bitwise_and(image, image, mask = white_mask)\n",
        "    \n",
        "    return masked_image\n",
        "\n",
        "def convert_hsv(image):\n",
        "\n",
        "    return cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "\n",
        "def HSV_color_selection(image):\n",
        "\n",
        "    #Convert the input image to HSV\n",
        "    converted_image = convert_hsv(image)\n",
        "    \n",
        "    #White color mask\n",
        "    lower_threshold = np.uint8([0, 0, 210])\n",
        "    upper_threshold = np.uint8([255, 30, 255])\n",
        "    white_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)\n",
        "\n",
        "    #Combine white and yellow masks\n",
        "    #mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
        "    masked_image = cv2.bitwise_and(image, image, mask = white_mask)\n",
        "    \n",
        "    return masked_image\n",
        "\n",
        "def convert_hsl(image):\n",
        "\n",
        "    return cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
        "\n",
        "\n",
        "def HSL_color_selection(image):\n",
        "\n",
        "    #Convert the input image to HSL\n",
        "    converted_image = convert_hsl(image)\n",
        "    \n",
        "    #White color mask\n",
        "    lower_threshold = np.uint8([0, 200, 0])\n",
        "    upper_threshold = np.uint8([255, 255, 255])\n",
        "    white_mask = cv2.inRange(converted_image, lower_threshold, upper_threshold)\n",
        "\n",
        "    #Combine white and yellow masks\n",
        "    #mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
        "    masked_image = cv2.bitwise_and(image, image, mask = white_mask)\n",
        "    \n",
        "    return masked_image\n",
        "\n",
        "def gray_scale(image):\n",
        "\n",
        "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "def gaussian_smoothing(image, kernel_size = 13):\n",
        "\n",
        "    return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n",
        "\n",
        "def canny_detector(image, low_threshold = 50, high_threshold = 150):\n",
        "\n",
        "    return cv2.Canny(image, low_threshold, high_threshold)\n",
        "\n",
        "def region_selection(image):\n",
        "\n",
        "    mask = np.zeros_like(image)   \n",
        "    #Defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
        "    if len(image.shape) > 2:\n",
        "        channel_count = image.shape[2]\n",
        "        ignore_mask_color = (255,) * channel_count\n",
        "    else:\n",
        "        ignore_mask_color = 255\n",
        "    #We could have used fixed numbers as the vertices of the polygon,\n",
        "    #but they will not be applicable to images with different dimesnions.\n",
        "    rows, cols = image.shape[:2]\n",
        "    #print(rows, cols, image.shape)\n",
        "    top_left     = [cols * 0.0, rows * 0.453]   # 950\n",
        "    bottom_left  = [cols * 0.0, rows * 0.495]   # 1075 (width, height)\n",
        "    bottom_right = [cols * 1.0, rows * 0.546]   # 1190 0r 300\n",
        "    top_right    = [cols * 1.0, rows * 0.500]   # 1060\n",
        "    vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)\n",
        "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
        "    masked_image = cv2.bitwise_and(image, mask)\n",
        "    return masked_image\n",
        "\n",
        "def hough_transform(image):\n",
        "    \"\"\"\n",
        "    Determine and cut the region of interest in the input image.\n",
        "        Parameters:\n",
        "            image: The output of a Canny transform.\n",
        "    \"\"\"\n",
        "    rho = 1              #Distance resolution of the accumulator in pixels.\n",
        "    theta = np.pi/180    #Angle resolution of the accumulator in radians.\n",
        "    threshold = 20       #Only lines that are greater than threshold will be returned.\n",
        "    minLineLength = 50   #Line segments shorter than that are rejected.\n",
        "    maxLineGap = 125     #Maximum allowed gap between points on the same line to link them\n",
        "    return cv2.HoughLinesP(image, rho = rho, theta = theta, threshold = threshold,\n",
        "                           minLineLength = minLineLength, maxLineGap = maxLineGap)\n",
        "\n",
        "\n",
        "def average_slope_intercept(lines):\n",
        "    \"\"\"\n",
        "    Find the slope and intercept of the left and right lanes of each image.\n",
        "        Parameters:\n",
        "            lines: The output lines from Hough Transform.\n",
        "    \"\"\"\n",
        "    left_lines    = [] #(slope, intercept)\n",
        "    left_weights  = [] #(length,)\n",
        "    right_lines   = [] #(slope, intercept)\n",
        "    right_weights = [] #(length,)\n",
        "    #print(\"length of points before=\",len(lines))\n",
        "    idx = -1\n",
        "    slopeIntercept = []\n",
        "    for idx1, line in enumerate(lines):\n",
        "        #print(line)\n",
        "        for x1, y1, x2, y2 in line:\n",
        "            length = np.sqrt(((y2 - y1) ** 2) + ((x2 - x1) ** 2))\n",
        "\n",
        "            if y1 > y2 or length > 150 or x1 == x2 or (y2-y1)>10:\n",
        "                continue\n",
        "            if idx1 > 0:\n",
        "                if (lines[idx1][0][1] - lines[idx1-1][0][3]) > 10: #(Y2 - Y1)\n",
        "                    continue\n",
        "                if (lines[idx1][0][1] - lines[idx1-1][0][3]) > 150:\n",
        "                    continue\n",
        "            '''param = np.polyfit((x1, x2), (y1, y2), 1) # (slope, intercept)=(param[0], param[1])\n",
        "            \n",
        "            if param[0] > 0.045:\n",
        "                continue '''\n",
        "\n",
        "            slope = (y2 - y1) / (x2 - x1)\n",
        "            intercept = y1 - (slope * x1)\n",
        "            if slope < 0 or slope == 0:\n",
        "                continue\n",
        "            else:\n",
        "                '''\n",
        "                right_lines.append([x1,y1,x2,y2])\n",
        "                #print(right_lines)\n",
        "                if  idx > 0:\n",
        "                    if abs(right_lines[idx][0] - right_lines[idx-1][0]) < 40:\n",
        "                        right_lines.pop(idx)\n",
        "                        idx -= 1\n",
        "                    param1 = np.polyfit((right_lines[idx-1][2], right_lines[idx][0]), (right_lines[idx-1][3], lines[idx][0][1]), 1)\n",
        "                    if param1[0] > 0.045 or param1[0] < 0.005:\n",
        "                        continue\n",
        "                    print(\"slope=\",param1[0])\n",
        "                    print(\"intercept=\",int(intercept),\"slope= %.3f\" % slope,\"length=\",int(length),right_lines[idx],(y2-y1) )\n",
        "            idx += 1'''\n",
        "                if idx1 > 0:\n",
        "                    '''if abs(lines[idx1][0][0] - lines[idx1-1][0][0]) < 100:\n",
        "                        continue'''\n",
        "                    '''param1 = np.polyfit((lines[idx1-1][0][2], lines[idx1][0][0]), (lines[idx1-1][0][3], lines[idx1][0][1]), 1)\n",
        "                    if param1[0] > 0.035 or param1[0] < 0.005:\n",
        "                        continue  '''\n",
        "                    right_lines.append([x1,y1,x2,y2])\n",
        "                    #print(\"intercept=\",int(intercept),\"slope= %.3f\" % slope,\"length=\",int(length),right_lines[idx],(y2-y1) )\n",
        "                else:\n",
        "                    right_lines.append([x1,y1,x2,y2])\n",
        "\n",
        "    return right_lines\n",
        "\n",
        "def pixel_points(y1, y2, line):\n",
        "\n",
        "    if line is None:\n",
        "        return None\n",
        "    slope, intercept = line\n",
        "    x1 = int((y1 - intercept)/slope)\n",
        "    x2 = int((y2 - intercept)/slope)\n",
        "    y1 = int(y1)\n",
        "    y2 = int(y2)\n",
        "    return ((x1, y1), (x2, y2))\n",
        "\n",
        "def lane_lines(image, lines):\n",
        "    right_lane = average_slope_intercept(lines)\n",
        "\n",
        "    return right_lane\n",
        "\n",
        "    \n",
        "def draw_lane_lines(image, lines, color=[0, 0, 255], thickness=6):\n",
        "\n",
        "    line_image = np.zeros_like(image)\n",
        "    #print(lines)\n",
        "    if lines is not None: \n",
        "        '''for [x1, y1, x2, y2] in lines: \n",
        "            cv2.line(line_image, (x1, y1), (x2, y2), color, thickness)   '''\n",
        "         \n",
        "        for idx, line in enumerate(lines): \n",
        "\n",
        "            cv2.line(line_image, (lines[idx][0], lines[idx][1]), (lines[idx][2], lines[idx][3]), color, thickness) \n",
        "            if idx > 0:\n",
        "                '''if lines[idx][3] - lines[idx-1][3] > 25:\n",
        "                    continue  '''\n",
        "                cv2.line(line_image, (lines[idx-1][2], lines[idx-1][3]), (lines[idx][0], lines[idx][1]), color, thickness) \n",
        "\n",
        "    return cv2.addWeighted(image, 1.0, line_image, 1.0, 0.0)\n",
        "             \n",
        "def align_image(img, S1, I1, S0, I0):\n",
        "    rows,cols = img.shape[:2]\n",
        "    #Shift in Y\n",
        "    Ty = -(I1-I0) ; Tx = 0\n",
        "    #Shift in X\n",
        "    #Tx = ((I1/S1)-(I0/S0))\n",
        "    Tx = 0\n",
        "    theta = -(S1 - S0)\n",
        "    #print(\"Tx, Ty =\",Tx,Ty, sy.cos(theta))\n",
        "    M = np.float32([[sy.cos(theta),sy.sin(theta),0],[sy.sin(theta),sy.cos(theta),Ty]])\n",
        "    dst = cv2.warpAffine(img,M,(cols,rows))\n",
        "    return dst\n",
        "    \n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # Path of dataset directory \n",
        "    path = '/content/drive/My Drive/Colab Notebooks/Videos/1stDrone.MP4'\n",
        "    #path = \"E:\\CodeVideoData\\ClipDroneData\\road_lane.mp4\"\n",
        "    cap = cv2.VideoCapture(path)  \n",
        "    print(\"Video Status: \",cap.isOpened())\n",
        "    #cv2.namedWindow(\"output\", cv2.WINDOW_NORMAL)\n",
        "    frame_count = 0\n",
        "    dist_dict = {}\n",
        "    frame_count = -1\n",
        "    #width = 1500; height = 820\n",
        "    width = 4096; height = 2160\n",
        "    #width = 4096; height = 432\n",
        "    #frate = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    frate = 30\n",
        "    #***************************************************************************************************************\n",
        "    path21 = '/content/drive/My Drive/Colab Notebooks/Colab Notebooks Anshu/Videos/_Track_laneLine_alignVideo_01.mp4' # Video write\n",
        "    writer = cv2.VideoWriter(path21, cv2.VideoWriter_fourcc(*'XVID'),frate, (width, height))\n",
        "    slopeIntercept = []\n",
        "    first_frame = True\n",
        "    while(cap.isOpened()):\n",
        "        ret, frame = cap.read()\n",
        "        frame_count += 1\n",
        "        if frame_count == 3600: # 3600\n",
        "          break\n",
        "\n",
        "        clip, img2   = clipVideo(frame)\n",
        "        color_select = HSL_color_selection(clip)\n",
        "        gray         = gray_scale(color_select)\n",
        "        smooth       = gaussian_smoothing(gray)\n",
        "        edges        = canny_detector(smooth)\n",
        "        region       = region_selection(edges)\n",
        "        hough        = hough_transform(region)\n",
        "\n",
        "        hough = hough.reshape(int(2*len(hough)),2)\n",
        "        hough.sort(axis=0) \n",
        "        hough = hough.reshape(len(hough)//2,1,4)\n",
        "        \n",
        "        #print(\"Number of points=\",len(hough))\n",
        "        laneLines   = lane_lines(clip, hough)\n",
        "        #print(\"length of points after\",len(laneLines))\n",
        "        laneLines = np.array(laneLines)\n",
        "        laneLines = laneLines.reshape(int(2*len(laneLines)),2)\n",
        "        if first_frame:\n",
        "            slope_1st, intercept_1st = regression(laneLines)\n",
        "            alignImage = align_image(frame, slope_1st, intercept_1st,slope_1st, intercept_1st)\n",
        "            first_frame = False\n",
        "            #print(\"Parameters=\",slope_1st, intercept_1st)\n",
        "        else:\n",
        "            slope, intercept = regression(laneLines)\n",
        "            alignImage = align_image(frame, slope, intercept, slope_1st, intercept_1st)\n",
        "\n",
        "        slopeIntercept = []\n",
        "\n",
        "        writer.write(frame)\n",
        "\n",
        "  \n",
        "    print(\"Finished\")\n",
        "    # destroy all the windows that is currently on \n",
        "    print(\"Frame Size=\",frame.shape)\n",
        "    cap.release() \n",
        "    writer.release()\n",
        "    cv2.destroyAllWindows()  \n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Video Status:  True\n",
            "Finished\n",
            "Frame Size= (2160, 4096, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJqijVBTYBwT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7b3c7ad6-dedf-4388-d263-2879068a3dc1"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Wed Jul 15 16:28:37 2020\n",
        "updated on July 15\n",
        "@author: KGaurav\n",
        "Title : Align Drone Video Frames\n",
        "Directory: Work\n",
        "\"\"\"\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "sys.path.insert(0, os.path.abspath(\"/content/drive/My Drive/Colab Notebooks/\"))\n",
        "from align import alignImages\n",
        "\n",
        "# Path of dataset directory \n",
        "#path = \"E:\\CodeVideoData\\_DroneData\\ClipDroneData\\_1stDrone.MP4\"  # _1stDrone_2~2\n",
        "print(\"INFO: Video Starting\")\n",
        "path = '/content/drive/My Drive/Colab Notebooks/Videos/3rdDrone.MP4'  # 1stDrone DJI_Morning\n",
        "cap = cv2.VideoCapture(path)  \n",
        "print(\"Video Status: \",cap.isOpened())\n",
        "\n",
        "#cv2.namedWindow(\"output\", cv2.WINDOW_NORMAL)\n",
        "frame_count = 0\n",
        "\n",
        "frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT ))\n",
        "#width = 1500; height = 820\n",
        "width = 4096; height = 2160\n",
        "#width = 4096; height = 432\n",
        "frate = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "#frate = 10\n",
        "#***************************************************************************************************************\n",
        "path21 = '/content/drive/My Drive/Colab Notebooks/Videos/_1stDrone_aligned.mp4' # Video write\n",
        "writer = cv2.VideoWriter(path21, cv2.VideoWriter_fourcc(*'XVID'),frate, (width, height))\n",
        "first_frame = True\n",
        "print(\"INFO: Aligning is in Progress...\",frames)\n",
        "\n",
        "while(cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "    frame_count += 1\n",
        "    if frame_count == 3660: # 10800,  3663\n",
        "      break\n",
        "    if first_frame:\n",
        "        imgRef = frame\n",
        "        first_frame = False\n",
        "    image = alignImages(frame , imgRef)\n",
        "    #result[0:864 ,] = frame[0:864, ] ;result[1296: ,] = frame[1296: ,]\n",
        "    #print(\"frame count = \",frame_count)\n",
        "    #cv2.imwrite(\"out/\" + str(frame_count) + \".jpg\",alignImage)\n",
        "    #cv2.imwrite(\"houghlines_result.jpg\",frame)\n",
        "    writer.write(image)\n",
        "\n",
        "  \n",
        "# destroy all the windows that is currently on \n",
        "print(\"Frame Size=\",image.shape)\n",
        "cap.release() \n",
        "writer.release()\n",
        "cv2.destroyAllWindows()  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO: Video Starting\n",
            "Video Status:  True\n",
            "INFO: Aligning is in Progress... 3669\n",
            "Frame Size= (2160, 4096, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0Ei3QlKdSfk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}